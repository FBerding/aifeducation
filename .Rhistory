set_config_os_environ_logger("ERROR")
#Load Embeddings
#object is imdb_embeddings
load(paste0(root_path_data,"/imdb_embeddings.rda"))
test_embeddings_large=imdb_embeddings$convert_to_LargeDataSetForTextEmbeddings()
test_embeddings=test_embeddings_large$convert_to_EmbeddedText()
test_embeddings_reduced=test_embeddings$clone(deep = TRUE)
test_embeddings_reduced$embeddings=test_embeddings_reduced$embeddings[1:5,,]
test_embeddings_reduced_LD=test_embeddings_reduced$convert_to_LargeDataSetForTextEmbeddings()
#case=sample(x=seq.int(from = 1,to=nrow(test_embeddings$embeddings)))
test_embeddings_single_case=test_embeddings$clone(deep = TRUE)
test_embeddings_single_case$embeddings=test_embeddings_single_case$embeddings[1,,,drop=FALSE]
test_embeddings_single_case_LD=test_embeddings_single_case$convert_to_LargeDataSetForTextEmbeddings()
#Config
ml_frameworks=c("pytorch")
rec_list=list(NULL,c(4),c(4,3))
rec_type_list=list("gru","lstm")
rec_bidirectiona_list=list(TRUE,FALSE)
hidden_list=list(NULL,c(4),c(4,3))
r_encoder_list=list(0,1,2)
attention_list=list("fourier","multihead")
pos_embedding_list=list(TRUE,FALSE)
sc_list=list(FALSE,TRUE)
pl_list=list(FALSE,TRUE)
#Load feature extractors
feature_extractor_list=NULL
feature_extractor_list["tensorflow"]=list(c(
load_from_disk(paste0(root_path_data,"/feature_extractor_tensorflow")),
NULL)
)
feature_extractor_list["tensorflow"]=list(c(
load_from_disk(paste0(root_path_data,"/feature_extractor_pytorch")),
NULL)
)
feature_extractor_list
feature_extractor_list=NULL
feature_extractor_list["tensorflow"]=list(
load_from_disk(paste0(root_path_data,"/feature_extractor_tensorflow")),
NULL)
feature_extractor_list["pytorch"]=list(
load_from_disk(paste0(root_path_data,"/feature_extractor_pytorch")),
NULL)
#Load feature extractors
feature_extractor_list=NULL
feature_extractor_list["tensorflow"]=list(c(
load_from_disk(paste0(root_path_data,"/feature_extractor_tensorflow")),
NULL)
)
feature_extractor_list
feature_extractor_list["tensorflow"]=list(list(
load_from_disk(paste0(root_path_data,"/feature_extractor_tensorflow")),
NULL)
)
feature_extractor_list
devtools::test_active_file()
reticulate::py_available(T)
devtools::load_all()
devtools::test_active_file()
devtools::load_all()
devtools::test_active_file()
devtools::test_active_file()
reticulate::py_available(T)
devtools::load_all()
#This file does not contain any tests. It is used for creating FeatureExtractors
#that can be used for testing Classifiers
#Config-------------------------------------------------------------------------
root_path_data=testthat::test_path("test_data/classifier")
if(dir.exists(root_path_data)==FALSE){
dir.create(root_path_data)
}
ml_frameworks<-c("tensorflow"#,
#"pytorch"
)
method_list="lstm"
load(testthat::test_path("test_data/classifier/imdb_embeddings.rda"))
dataset_list=list("EmbeddedText"=imdb_embeddings,
"LargeDataSetForTextEmbeddings"=imdb_embeddings$convert_to_LargeDataSetForTextEmbeddings())
trace=TRUE
#Start creation and training---------------------------------------------------
for(framework in ml_frameworks){
for(method in method_list){
train_path=paste0(root_path_data)
extractor<-TEFeatureExtractor$new(
ml_framework = framework,
name="Test_extractor",
label="Test Extractor",
text_embeddings=dataset_list[["LargeDataSetForTextEmbeddings"]],
features=128,
method=method,
noise_factor=0.2,
optimizer="adam"
)
extractor$train(
data_embeddings=dataset_list[["LargeDataSetForTextEmbeddings"]],
data_val_size=0.25,
sustain_track=TRUE,
sustain_iso_code="DEU",
sustain_region=NULL,
sustain_interval=15,
epochs=500,
batch_size=100,
dir_checkpoint=train_path,
trace=trace,
keras_trace=1,
pytorch_trace=1
)
save_to_disk(object = extractor,
model_dir = root_path_data,
folder_name = paste0("feature_extractor_",framework))
}
}
devtools::test_active_file()
rlang::last_trace()
devtools::test_active_file()
devtools::load_all()
#This file does not contain any tests. It is used for creating FeatureExtractors
#that can be used for testing Classifiers
#Config-------------------------------------------------------------------------
root_path_data=testthat::test_path("test_data/classifier")
if(dir.exists(root_path_data)==FALSE){
dir.create(root_path_data)
}
ml_frameworks<-c(#"tensorflow"#,
"pytorch"
)
method_list="lstm"
load(testthat::test_path("test_data/classifier/imdb_embeddings.rda"))
dataset_list=list("EmbeddedText"=imdb_embeddings,
"LargeDataSetForTextEmbeddings"=imdb_embeddings$convert_to_LargeDataSetForTextEmbeddings())
trace=TRUE
#Start creation and training---------------------------------------------------
for(framework in ml_frameworks){
for(method in method_list){
train_path=paste0(root_path_data)
extractor<-TEFeatureExtractor$new(
ml_framework = framework,
name="Test_extractor",
label="Test Extractor",
text_embeddings=dataset_list[["LargeDataSetForTextEmbeddings"]],
features=128,
method=method,
noise_factor=0.2,
optimizer="adam"
)
extractor$train(
data_embeddings=dataset_list[["LargeDataSetForTextEmbeddings"]],
data_val_size=0.25,
sustain_track=TRUE,
sustain_iso_code="DEU",
sustain_region=NULL,
sustain_interval=15,
epochs=500,
batch_size=100,
dir_checkpoint=train_path,
trace=trace,
keras_trace=1,
pytorch_trace=1
)
save_to_disk(object = extractor,
model_dir = root_path_data,
folder_name = paste0("feature_extractor_",framework))
}
}
reticulate::py_available(T)
devtools::load_all()
devtools::test_active_file()
devtools::test_active_file()
devtools::test_active_file()
is.vector(50)
check_class(hidden, 50, TRUE)
check_class(50, c("vector"), TRUE)
class(50)
is.vector(50)
devtools::test_active_file()
framework="pytorch"
testthat::skip_if_not(condition=check_aif_py_modules(trace = FALSE),
message  = "Necessary python modules not available")
#Skip Tests
skip_creation_test=FALSE
skip_training_test=TRUE
skip_overfitting_test=TRUE
#SetUp-------------------------------------------------------------------------
#Set paths
root_path_data=testthat::test_path("test_data/classifier")
if(dir.exists(testthat::test_path("test_artefacts"))==FALSE){
dir.create(testthat::test_path("test_artefacts"))
}
root_path_results=testthat::test_path("test_artefacts/TeClassifierRegular")
if(dir.exists(root_path_results)==FALSE){
dir.create(root_path_results)
}
#SetUp datasets
#Disable tqdm progressbar
transformers$logging$disable_progress_bar()
datasets$disable_progress_bars()
#SetUp tensorflow
aifeducation::set_config_gpu_low_memory()
set_config_tf_logger("ERROR")
set_config_os_environ_logger("ERROR")
#Load Embeddings
#object is imdb_embeddings
load(paste0(root_path_data,"/imdb_embeddings.rda"))
test_embeddings_large=imdb_embeddings$convert_to_LargeDataSetForTextEmbeddings()
test_embeddings=test_embeddings_large$convert_to_EmbeddedText()
test_embeddings_reduced=test_embeddings$clone(deep = TRUE)
test_embeddings_reduced$embeddings=test_embeddings_reduced$embeddings[1:5,,]
test_embeddings_reduced_LD=test_embeddings_reduced$convert_to_LargeDataSetForTextEmbeddings()
#case=sample(x=seq.int(from = 1,to=nrow(test_embeddings$embeddings)))
test_embeddings_single_case=test_embeddings$clone(deep = TRUE)
test_embeddings_single_case$embeddings=test_embeddings_single_case$embeddings[1,,,drop=FALSE]
test_embeddings_single_case_LD=test_embeddings_single_case$convert_to_LargeDataSetForTextEmbeddings()
#Config
ml_frameworks=c("tensorflow","pytorch")
rec_list=list(NULL,c(4),c(4,3))
rec_type_list=list("gru","lstm")
rec_bidirectiona_list=list(TRUE,FALSE)
hidden_list=list(NULL,c(4),c(4,3))
r_encoder_list=list(0,1,2)
attention_list=list("fourier","multihead")
pos_embedding_list=list(TRUE,FALSE)
sc_list=list(FALSE,TRUE)
pl_list=list(FALSE,TRUE)
#Load feature extractors
feature_extractor_list=NULL
feature_extractor_list["tensorflow"]=list(list(NULL))
feature_extractor_list["pytorch"]=list(list(
load_from_disk(paste0(root_path_data,"/feature_extractor_pytorch")),
NULL)
)
#Create feature extractors
#feature_extractor_list=NULL
#for(framework in ml_frameworks){
#  checkpoint_path=paste0(root_path_results,"/",framework,"_fe")
#  extractor<-TEFeatureExtractor$new(
#    ml_framework = framework,
#    name="Test_extractor",
#    label="Test Extractor",
#    text_embeddings=test_embeddings,
#    features=128,
#    method="lstm",
#    noise_factor=0.01,
#    optimizer="adam"
#  )
#  if(dir.exists(checkpoint_path)==FALSE){
#    dir.create(checkpoint_path)
#  }
#  extractor$train(
#    data_embeddings=test_embeddings,
#    data_val_size=0.25,
#    sustain_track=TRUE,
#    sustain_iso_code="DEU",
#    sustain_region=NULL,
#    sustain_interval=15,
#    epochs=2,
#    batch_size=100,
#    dir_checkpoint=checkpoint_path,
#    trace=FALSE,
#    keras_trace=0,
#    pytorch_trace=0
#  )
#  feature_extractor_list[framework]=list(c(extractor,NULL))
#}
n_classes=2
#Prepare data for different classification types---------------------------
example_data<-imdb_movie_reviews
rownames(example_data)<-rownames(test_embeddings$embeddings)
example_data$id<-rownames(test_embeddings$embeddings)
example_data<-example_data[intersect(
rownames(example_data),rownames(test_embeddings$embeddings)),]
example_data$label<-as.character(example_data$label)
example_data$label[c(201:300)]=NA
if(n_classes>2){
example_data$label[c(201:250)]<-"medium"
}
example_targets<-as.factor(example_data$label)
names(example_targets)=example_data$id
feature_extractor=NULL
hidden=NULL
rec=NULL
rec_type="lstm"
rec_bidirectional=TRUE
pos_embedding=FALSE
attention="fourier"
r=0
classifier<-TEClassifierRegular$new(
ml_framework = framework,
name="movie_review_classifier",
label="Classifier for Estimating a Postive or Negative Rating of Movie Reviews",
text_embeddings=test_embeddings,
feature_extractor=feature_extractor,
targets=example_targets,
hidden=hidden,
rec=rec,
rec_type = rec_type,
rec_bidirectional=rec_bidirectional,
self_attention_heads = 2,
add_pos_embedding = pos_embedding,
attention_type =  attention,
encoder_dropout = 0.1,
repeat_encoder = r,
recurrent_dropout=0.4)
test_that(paste("no sustainability tracking",framework,
"n_classes",n_classes,
"features_extractor",!is.null(feature_extractor),
"rec",paste(rec,collapse = "_"),
"rec_type",rec_type,
"rec_bidirectional",rec_bidirectional,
"hidden",paste(hidden,collapse = "_"),
"encoder",r,
"attention",attention,
"pos",pos_embedding),{
expect_false(classifier$get_sustainability_data()$sustainability_tracked)
})
test_that(paste("predict - basic",framework,
"n_classes",n_classes,
"features_extractor",!is.null(feature_extractor),
"rec",paste(rec,collapse = "_"),
"rec_type",rec_type,
"rec_bidirectional",rec_bidirectional,
"hidden",paste(hidden,collapse = "_"),
"encoder",r,
"attention",attention,
"pos",pos_embedding),
{
expect_s3_class(classifier,
class="TEClassifierRegular")
predictions=classifier$predict(
newdata = test_embeddings_reduced,
batch_size = 2,
verbose = 0)
expect_equal(object = length(predictions$expected_category),
expected = nrow(test_embeddings_reduced$embeddings))
})
test_that(paste("predict - single case", framework,
"n_classes",n_classes,
"features_extractor",!is.null(feature_extractor),
"rec",paste(rec,collapse = "_"),
"rec_type",rec_type,
"rec_bidirectional",rec_bidirectional,
"hidden",paste(hidden,collapse = "_"),
"encoder",r,
"attention",attention,
"pos",pos_embedding), {
prediction<-classifier$predict(newdata = test_embeddings_single_case,
batch_size = 2,
verbose = 0)
expect_equal(object=nrow(prediction),
expected = 1)
prediction_LD<-classifier$predict(newdata = test_embeddings_single_case_LD,
batch_size = 2,
verbose = 0)
expect_equal(object=nrow(prediction_LD),
expected = 1)
})
test_that(paste("predict - randomness",framework,
"n_classes",n_classes,
"features_extractor",!is.null(feature_extractor),
"rec",paste(rec,collapse = "_"),
"rec_type",rec_type,
"rec_bidirectional",rec_bidirectional,
"hidden",paste(hidden,collapse = "_"),
"encoder",r,
"attention",attention,
"pos",pos_embedding),
{
#EmbeddedText
predictions=classifier$predict(
newdata = test_embeddings_reduced,
batch_size = 2,
verbose = 0)
predictions_2=classifier$predict(
newdata = test_embeddings_reduced,
batch_size = 2,
verbose = 0)
expect_equal(predictions,predictions_2)
#LargeDataSetForTextEmbeddings
predictions=classifier$predict(
newdata = test_embeddings_reduced_LD,
batch_size = 2,
verbose = 0)
predictions_2=classifier$predict(
newdata = test_embeddings_reduced_LD,
batch_size = 2,
verbose = 0)
expect_equal(predictions,predictions_2)
})
test_that(paste("predict - order invariance",framework,
"n_classes",n_classes,
"features_extractor",!is.null(feature_extractor),
"rec",paste(rec,collapse = "_"),
"rec_type",rec_type,
"rec_bidirectional",rec_bidirectional,
"hidden",paste(hidden,collapse = "_"),
"encoder",r,
"attention",attention,
"pos",pos_embedding),
{
embeddings_ET_perm=test_embeddings_reduced$clone(deep=TRUE)
perm=sample(x=seq.int(from = 1,to=nrow(embeddings_ET_perm$embeddings)),replace = FALSE)
embeddings_ET_perm$embeddings=embeddings_ET_perm$embeddings[perm,,,drop=FALSE]
#EmbeddedText
predictions=classifier$predict(newdata = test_embeddings_reduced,
batch_size = 50,
verbose = 0)
predictions_Perm<-classifier$predict(newdata = embeddings_ET_perm,
batch_size = 50,
verbose = 0)
i=sample(seq.int(from = 1,to=nrow(predictions)),size = 1)
predictions_Perm=predictions_Perm[names(predictions)]
expect_equal(predictions$expected_category, predictions_Perm$expected_category)
#LargeDataSetForTextEmbeddings
predictions=classifier$predict(newdata = test_embeddings_reduced_LD,
batch_size = 50,
verbose = 0)
predictions_Perm=classifier$predict(newdata = embeddings_ET_perm$convert_to_LargeDataSetForTextEmbeddings(),
batch_size = 50,
verbose = 0)
i=sample(seq.int(from = 1,to=nrow(predictions)),size = 1)
expect_equal(predictions$expected_category, predictions_Perm$expected_category)
})
embeddings_ET_perm=test_embeddings_reduced$clone(deep=TRUE)
perm=sample(x=seq.int(from = 1,to=nrow(embeddings_ET_perm$embeddings)),replace = FALSE)
embeddings_ET_perm$embeddings=embeddings_ET_perm$embeddings[perm,,,drop=FALSE]
names(embeddings_ET_perm$embeddings)
rownames(embeddings_ET_perm$embeddings)
rownames(test_embeddings_reduced$embeddings)
#EmbeddedText
predictions=classifier$predict(newdata = test_embeddings_reduced,
batch_size = 50,
verbose = 0)
predictions_Perm<-classifier$predict(newdata = embeddings_ET_perm,
batch_size = 50,
verbose = 0)
predictions
predictions_Perm
predictions_Perm=predictions_Perm[names(predictions)]
predictions_Perm
predictions
predictions_Perm=predictions_Perm[names(predictions),,,drop=FALSE]
predictions_Perm=predictions_Perm[names(predictions),,drop=FALSE]
predictions_Perm
names(predictions)
embeddings_ET_perm=test_embeddings_reduced$clone(deep=TRUE)
perm=sample(x=seq.int(from = 1,to=nrow(embeddings_ET_perm$embeddings)),replace = FALSE)
embeddings_ET_perm$embeddings=embeddings_ET_perm$embeddings[perm,,,drop=FALSE]
#EmbeddedText
predictions=classifier$predict(newdata = test_embeddings_reduced,
batch_size = 50,
verbose = 0)
predictions_Perm<-classifier$predict(newdata = embeddings_ET_perm,
batch_size = 50,
verbose = 0)
predictions_Perm=predictions_Perm[rownames(predictions)]
predictions_Perm=predictions_Perm[rownames(predictions),]
expect_equal(predictions$expected_category, predictions_Perm$expected_category)
devtools::test_active_file()
c
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::check()
devtools::check()
devtools::check()
.Last.error
devtools::check()
devtools::check()
devtools::check()
devtools::document()
devtools::check()
devtools::document()
#Deprecation Warning
.Deprecated()
Siehe help("Deprecated")
help("Deprecated")
#Deprecation Warning
.Deprecated("test")
devtools::document()
devtools::document()
devtools::test_active_file()
styler::style_file()
styler:::style_active_file()
styler:::style_active_file()
styler:::style_active_file()
styler:::style_active_file()
devtools::test_active_file()
devtools::test_active_file()
devtools::test_active_file()
devtools::test_active_file()
devtools::test_active_file()
devtools::test_active_file()
devtools::test_active_file()
devtools::test_active_file()
devtools::test_active_file()
devtools::test_active_file()
devtools::test_active_file()
devtools::document()
_
devtools::document()
devtools::document()
devtools::test_active_file()
devtools::test_active_file()
install_py_modules(envname = "numpy2",install = "all")
reticulate::use_condaenv("numpy2")
reticulate::py_config()
devtools::test_active_file()
devtools::load_all()
devtools::test_active_file()
