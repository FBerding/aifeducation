bert_modeling<-TextEmbeddingModel$new(
model_name=paste0(ai_method,"_embedding"),
model_label=paste0("Text Embedding via",ai_method),
model_version="0.0.1",
model_language="english",
method = ai_method,
ml_framework=framework,
max_length = 256,
chunks=4,
overlap=10,
aggregation="last",
model_dir=path_01)
)
bert_modeling<-TextEmbeddingModel$new(
model_name=paste0(ai_method,"_embedding"),
model_label=paste0("Text Embedding via",ai_method),
model_version="0.0.1",
model_language="english",
method = ai_method,
ml_framework=framework,
max_length = 256,
chunks=4,
overlap=10,
aggregation="last",
model_dir=path_01)
tokens<-bert_modeling$get_special_tokens()
tokens
expect_type(tokens,type="matrix")
tokens<-bert_modeling$get_special_tokens()
expect_type(tokens,type="matrix")
class(tokens)
expect_s4_class(tokens,"matrix")
expect_s3_class(tokens,"matrix")
expect_equal(nrow(tokens),7)
expect_equal(ncol(tokens),3)
which(tokens[,1]=="mask_token")
mask_token<-[tokens[which(tokens[,1]=="mask_token"),1]]
mask_token<-tokens[which(tokens[,1]=="mask_token"),1]
mask_token
mask_token<-tokens[which(tokens[,2]=="mask_token"),1]
mask_token
tokens
mask_token<-tokens[which(tokens[,1]=="mask_token"),2]
mask_token
fist_solution<-bert_modeling$fill_mask(text=paste("This is a",mask_token,"."),
n_solutions = 5)
fist_solution
fist_solution[[1]]
type(fist_solution[[1]])
class(fist_solution[[1]])
expect_true(is.data.frame(first_solution))
first_solution<-bert_modeling$fill_mask(text=paste("This is a",mask_token,"."),
n_solutions = 5)
expect_true(is.data.frame(first_solution))
expect_equal(length(first_solution),1)
expect_true(is.data.frame(first_solution[[1]]))
expect_equal(nrow(first_solution[[1]],5)
})
expect_equal(nrow(first_solution[[1]]),5)
second_solution<-bert_modeling$fill_mask(text=paste("This is a",mask_token,"."),
n_solutions = 1)
expect_equal(length(second_solution),1)
expect_true(is.data.frame(second_solution[[1]]))
expect_equal(nrow(second_solution[[1]]),5)
expect_equal(nrow(second_solution[[1]]),1)
expect_equal(ncol(second_solution[[1]]),3)
second_solution
expect_equal(length(third_solution),2)
third_solution<-bert_modeling$fill_mask(text=paste("This is a",mask_token,".",
"The wheater is",mask_token,"."),
n_solutions = 5)
expect_equal(length(third_solution),2)
for(i in 1:2){
expect_true(is.data.frame(third_solution[[i]]))
expect_equal(nrow(third_solution[[i]]),5)
expect_equal(ncol(third_solution[[i]]),3)
}
devtools::load_all()
runApp('Trial/aif_gui.R')
runApp('Trial/aif_gui.R')
runApp('Trial/aif_gui.R')
runApp('Trial/aif_gui.R')
devtools::load_all()
runApp('Trial/aif_gui.R')
runApp('Trial/aif_gui.R')
devtools::load_all()
runApp('Trial/aif_gui.R')
devtools::test_active_file()
devtools::load_all()
devtools::test_active_file()
tok_new<-tok$SentencePieceUnigramTokenizer()
devtools::load_all()
devtools::test_active_file()
devtools::load_all()
devtools::test_active_file()
reticulate::py_available(T)
devtools::load_all()
testthat::skip_on_cran()
testthat::skip_if_not(condition=check_aif_py_modules(trace = FALSE),
message = "Necessary python modules not available")
if(aifeducation_config$global_framework_set()==FALSE){
aifeducation_config$set_global_ml_backend("tensorflow")
}
aifeducation::set_config_gpu_low_memory()
#transformers$utils$logging$set_verbosity_warning()
transformers$utils$logging$set_verbosity_error()
os$environ$setdefault("TOKENIZERS_PARALLELISM","false")
set_config_tf_logger("ERROR")
set_config_os_environ_logger("ERROR")
if(dir.exists(testthat::test_path("test_artefacts"))==FALSE){
dir.create(testthat::test_path("test_artefacts"))
}
if(dir.exists(testthat::test_path("test_artefacts/tmp"))==FALSE){
dir.create(testthat::test_path("test_artefacts/tmp"))
}
ml_frameworks<-c("tensorflow",
"pytorch")
ai_methods=c("bert",
"roberta",
"longformer",
"funnel",
"deberta_v2"
)
ai_framework_matrix<-matrix(
ncol=2,
nrow=length(ai_methods),
data=c(1,1,
1,1,
1,1,
1,1,
1,1),
byrow=TRUE)
colnames(ai_framework_matrix)<-c("tensorflow","pytorch")
rownames(ai_framework_matrix)<-ai_methods
rows_susatainability<-vector(length = length(ai_methods))
names(rows_susatainability)<-ai_methods
rows_susatainability["bert"]=3
rows_susatainability["funnel"]=2
rows_susatainability["roberta"]=2
rows_susatainability["longformer"]=2
rows_susatainability["deberta_v2"]=2
example_data<-data.frame(
id=quanteda::docvars(quanteda.textmodels::data_corpus_moviereviews)$id1,
label=quanteda::docvars(quanteda.textmodels::data_corpus_moviereviews)$sentiment)
example_data$text<-as.character(quanteda.textmodels::data_corpus_moviereviews)
framework="pytorch"
ai_method="bert"
base::gc(verbose = FALSE,full = TRUE)
path_01=paste0("test_artefacts/",ai_method)
if(dir.exists(testthat::test_path(path_01))==FALSE){
dir.create(testthat::test_path(path_01))
}
path_02=paste0("test_artefacts/tmp/",ai_method)
path_03=paste0("test_artefacts/tmp_full_models")
if(dir.exists(testthat::test_path(path_02))==FALSE){
dir.create(testthat::test_path(path_02))
}
if(dir.exists(testthat::test_path(path_03))==FALSE){
dir.create(testthat::test_path(path_03))
}
if(dir.exists(testthat::test_path(paste0(path_03,"/tensorflow")))==FALSE){
dir.create(testthat::test_path(paste0(path_03,"/tensorflow")))
}
if(dir.exists(testthat::test_path(paste0(path_03,"/pytorch")))==FALSE){
dir.create(testthat::test_path(paste0(path_03,"/pytorch")))
}
expect_no_error(
create_bert_model(
ml_framework = framework,
model_dir=testthat::test_path(paste0(path_01,"/",framework)),
vocab_raw_texts=example_data$text,
vocab_size=50000,
vocab_do_lower_case=FALSE,
max_position_embeddings=512,
hidden_size=256,
num_hidden_layer=2,
num_attention_heads=2,
intermediate_size=256,
hidden_act="gelu",
hidden_dropout_prob=0.1,
sustain_track=TRUE,
sustain_iso_code = "DEU",
sustain_region = NULL,
sustain_interval = 15,
trace=FALSE))
expect_no_error(
train_tune_bert_model(ml_framework = framework,
output_dir=testthat::test_path(paste0(path_01,"/",framework)),
model_dir_path=testthat::test_path(paste0(path_01,"/",framework)),
raw_texts= example_data$text[1:10],
p_mask=0.15,
whole_word=TRUE,
full_sequences_only = TRUE,
val_size=0.25,
n_epoch=2,
batch_size=2,
chunk_size=100,
n_workers=1,
multi_process=FALSE,
sustain_track=TRUE,
sustain_iso_code = "DEU",
sustain_region = NULL,
sustain_interval = 15,
trace=FALSE,
keras_trace = 0))
devtools::load_all()
expect_no_error(
train_tune_bert_model(ml_framework = framework,
output_dir=testthat::test_path(paste0(path_01,"/",framework)),
model_dir_path=testthat::test_path(paste0(path_01,"/",framework)),
raw_texts= example_data$text[1:10],
p_mask=0.15,
whole_word=TRUE,
full_sequences_only = TRUE,
val_size=0.25,
n_epoch=2,
batch_size=2,
chunk_size=100,
n_workers=1,
multi_process=FALSE,
sustain_track=TRUE,
sustain_iso_code = "DEU",
sustain_region = NULL,
sustain_interval = 15,
trace=FALSE,
keras_trace = 0))
reticulate::py_module_available("safetensors")
devtools::load_all()
devtools::test_active_file()
devtools::load_all()
testthat::skip_if_not(condition=check_aif_py_modules(trace = FALSE),
message  = "Necessary python modules not available")
aifeducation::set_config_gpu_low_memory()
set_config_tf_logger("ERROR")
set_config_os_environ_logger("ERROR")
path="test_data/classifier/bert_embeddings.rda"
testthat::skip_if_not(condition=file.exists(testthat::test_path(path)),
message  = "Necessary dataset not available")
if(dir.exists(testthat::test_path("test_artefacts"))==FALSE){
dir.create(testthat::test_path("test_artefacts"))
}
if(dir.exists(testthat::test_path("test_artefacts/tmp_full_models"))==FALSE){
dir.create(testthat::test_path("test_artefacts/tmp_full_models"))
}
if(dir.exists(testthat::test_path("test_artefacts/classifier"))==FALSE){
dir.create(testthat::test_path("test_artefacts/classifier"))
}
if(dir.exists(testthat::test_path("test_artefacts/tmp"))==FALSE){
dir.create(testthat::test_path("test_artefacts/tmp"))
}
if(dir.exists(testthat::test_path("test_artefacts/tmp/2_classes"))==FALSE){
dir.create(testthat::test_path("test_artefacts/tmp/2_classes"))
}
if(dir.exists(testthat::test_path("test_artefacts/tmp/3_classes"))==FALSE){
dir.create(testthat::test_path("test_artefacts/tmp/3_classes"))
}
folder_list=c("keras","pytorch")
for (folder in folder_list){
if(dir.exists(testthat::test_path(paste0("test_artefacts/tmp_full_models_",folder)))==FALSE){
dir.create(testthat::test_path(paste0("test_artefacts/tmp_full_models_",folder)))
}
if(dir.exists(testthat::test_path(paste0("test_artefacts/tmp_",folder)))==FALSE){
dir.create(testthat::test_path(paste0("test_artefacts/tmp_",folder)))
}
if(dir.exists(testthat::test_path(paste0("test_artefacts/tmp_",folder,"/2_classes")))==FALSE){
dir.create(testthat::test_path(paste0("test_artefacts/tmp_",folder,"/2_classes")))
}
if(dir.exists(testthat::test_path(paste0("test_artefacts/tmp_",folder,"/3_classes")))==FALSE){
dir.create(testthat::test_path(paste0("test_artefacts/tmp_",folder,"/3_classes")))
}
}
ml_frameworks=c("tensorflow","pytorch")
#-------------------------------------------------------------------------------
aifeducation::set_config_gpu_low_memory()
load(testthat::test_path(path))
current_embeddings<-bert_embeddings$clone(deep = TRUE)
n_classes=2
example_data<-data.frame(
id=quanteda::docvars(quanteda.textmodels::data_corpus_moviereviews)$id2,
label=quanteda::docvars(quanteda.textmodels::data_corpus_moviereviews)$sentiment)
example_data$text<-as.character(quanteda.textmodels::data_corpus_moviereviews)
example_data$label<-as.character(example_data$label)
rownames(example_data)<-example_data$id
example_data<-example_data[intersect(
rownames(example_data),rownames(current_embeddings$embeddings)),]
example_data$label[c(201:300)]=NA
if(n_classes>2){
example_data$label[c(201:250)]<-"medium"
}
example_targets<-as.factor(example_data$label)
names(example_targets)=example_data$id
rec_list=list(NULL,c(28),c(28,14))
hidden_list=list(NULL,c(27),c(27,13))
r_encoder_list=list(0,1,2)
attention_list=list("fourier","multihead")
pos_embedding_list=list(TRUE,FALSE)
framework="tensorflow"
for(rec in rec_list){
for(hidden in hidden_list){
for(r in r_encoder_list){
for(attention in attention_list){
for(pos_embedding in pos_embedding_list){
test_that(paste(framework,"creation_classifier_neural_net","n_classes",n_classes,
"rec",paste(rec,collapse = "_"),"hidden",paste(hidden,collapse = "_"),"encoder",r,"attention",attention,"pos",pos_embedding), {
classifier<-NULL
classifier<-TextEmbeddingClassifierNeuralNet$new(
ml_framework = framework,
name="movie_review_classifier",
label="Classifier for Estimating a Postive or Negative Rating of Movie Reviews",
text_embeddings=current_embeddings,
targets=example_targets,
hidden=hidden,
rec=rec,
self_attention_heads = 2,
add_pos_embedding = pos_embedding,
attention_type =  attention,
encoder_dropout = 0.1,
repeat_encoder = r,
recurrent_dropout=0.4)
expect_s3_class(classifier,
class="TextEmbeddingClassifierNeuralNet")
predictions=classifier$predict(
newdata = current_embeddings$embeddings[1:3,,],
batch_size = 2,
verbose = 0)
expect_equal(object = length(predictions$expected_category),expected = 3)
expect_false(classifier$get_sustainability_data()$sustainability_tracked)
})
}
}
}
}
}
devtools::load_all()
for(rec in rec_list){
for(hidden in hidden_list){
for(r in r_encoder_list){
for(attention in attention_list){
for(pos_embedding in pos_embedding_list){
test_that(paste(framework,"creation_classifier_neural_net","n_classes",n_classes,
"rec",paste(rec,collapse = "_"),"hidden",paste(hidden,collapse = "_"),"encoder",r,"attention",attention,"pos",pos_embedding), {
classifier<-NULL
classifier<-TextEmbeddingClassifierNeuralNet$new(
ml_framework = framework,
name="movie_review_classifier",
label="Classifier for Estimating a Postive or Negative Rating of Movie Reviews",
text_embeddings=current_embeddings,
targets=example_targets,
hidden=hidden,
rec=rec,
self_attention_heads = 2,
add_pos_embedding = pos_embedding,
attention_type =  attention,
encoder_dropout = 0.1,
repeat_encoder = r,
recurrent_dropout=0.4)
expect_s3_class(classifier,
class="TextEmbeddingClassifierNeuralNet")
predictions=classifier$predict(
newdata = current_embeddings$embeddings[1:3,,],
batch_size = 2,
verbose = 0)
expect_equal(object = length(predictions$expected_category),expected = 3)
expect_false(classifier$get_sustainability_data()$sustainability_tracked)
})
}
}
}
}
}
classifier<-NULL
classifier<-TextEmbeddingClassifierNeuralNet$new(
ml_framework = framework,
name="movie_review_classifier",
label="Classifier for Estimating a Postive or Negative Rating of Movie Reviews",
text_embeddings=current_embeddings,
targets=example_targets,
hidden=hidden,
rec=rec,
self_attention_heads = 2,
add_pos_embedding = pos_embedding,
attention_type =  attention,
encoder_dropout = 0.1,
repeat_encoder = r,
recurrent_dropout=0.4)
classifier$model$summary()
devtools::load_all()
for(rec in rec_list){
for(hidden in hidden_list){
for(r in r_encoder_list){
for(attention in attention_list){
for(pos_embedding in pos_embedding_list){
test_that(paste(framework,"creation_classifier_neural_net","n_classes",n_classes,
"rec",paste(rec,collapse = "_"),"hidden",paste(hidden,collapse = "_"),"encoder",r,"attention",attention,"pos",pos_embedding), {
classifier<-NULL
classifier<-TextEmbeddingClassifierNeuralNet$new(
ml_framework = framework,
name="movie_review_classifier",
label="Classifier for Estimating a Postive or Negative Rating of Movie Reviews",
text_embeddings=current_embeddings,
targets=example_targets,
hidden=hidden,
rec=rec,
self_attention_heads = 2,
add_pos_embedding = pos_embedding,
attention_type =  attention,
encoder_dropout = 0.1,
repeat_encoder = r,
recurrent_dropout=0.4)
expect_s3_class(classifier,
class="TextEmbeddingClassifierNeuralNet")
predictions=classifier$predict(
newdata = current_embeddings$embeddings[1:3,,],
batch_size = 2,
verbose = 0)
expect_equal(object = length(predictions$expected_category),expected = 3)
expect_false(classifier$get_sustainability_data()$sustainability_tracked)
})
}
}
}
}
}
rec_list=list(NULL,c(28),c(28,14))
hidden_list=list(NULL,c(27),c(27,13))
r_encoder_list=list(0,1,2)
attention_list=list("fourier","multihead")
pos_embedding_list=list(TRUE,FALSE)
for(rec in rec_list){
for(hidden in hidden_list){
for(r in r_encoder_list){
for(attention in attention_list){
for(pos_embedding in pos_embedding_list){
test_that(paste(framework,"creation_classifier_neural_net","n_classes",n_classes,
"rec",paste(rec,collapse = "_"),"hidden",paste(hidden,collapse = "_"),"encoder",r,"attention",attention,"pos",pos_embedding), {
classifier<-NULL
classifier<-TextEmbeddingClassifierNeuralNet$new(
ml_framework = framework,
name="movie_review_classifier",
label="Classifier for Estimating a Postive or Negative Rating of Movie Reviews",
text_embeddings=current_embeddings,
targets=example_targets,
hidden=hidden,
rec=rec,
self_attention_heads = 2,
add_pos_embedding = pos_embedding,
attention_type =  attention,
encoder_dropout = 0.1,
repeat_encoder = r,
recurrent_dropout=0.4)
expect_s3_class(classifier,
class="TextEmbeddingClassifierNeuralNet")
predictions=classifier$predict(
newdata = current_embeddings$embeddings[1:3,,],
batch_size = 2,
verbose = 0)
expect_equal(object = length(predictions$expected_category),expected = 3)
expect_false(classifier$get_sustainability_data()$sustainability_tracked)
})
}
}
}
}
}
classifier$model_config$repeat_encoder
devtools::load_all()
for(rec in rec_list){
for(hidden in hidden_list){
for(r in r_encoder_list){
for(attention in attention_list){
for(pos_embedding in pos_embedding_list){
test_that(paste(framework,"creation_classifier_neural_net","n_classes",n_classes,
"rec",paste(rec,collapse = "_"),"hidden",paste(hidden,collapse = "_"),"encoder",r,"attention",attention,"pos",pos_embedding), {
classifier<-NULL
classifier<-TextEmbeddingClassifierNeuralNet$new(
ml_framework = framework,
name="movie_review_classifier",
label="Classifier for Estimating a Postive or Negative Rating of Movie Reviews",
text_embeddings=current_embeddings,
targets=example_targets,
hidden=hidden,
rec=rec,
self_attention_heads = 2,
add_pos_embedding = pos_embedding,
attention_type =  attention,
encoder_dropout = 0.1,
repeat_encoder = r,
recurrent_dropout=0.4)
expect_s3_class(classifier,
class="TextEmbeddingClassifierNeuralNet")
predictions=classifier$predict(
newdata = current_embeddings$embeddings[1:3,,],
batch_size = 2,
verbose = 0)
expect_equal(object = length(predictions$expected_category),expected = 3)
expect_false(classifier$get_sustainability_data()$sustainability_tracked)
})
}
}
}
}
}
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
start_aifeducation_studio()
devtools::load_all()
start_aifeducation_studio()
