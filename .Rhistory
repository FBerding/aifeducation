use_baseline=TRUE,
bsl_val_size=0.25,
use_bsc=FALSE,
bsc_methods=c("dbsmote"),
bsc_max_k=10,
bsc_val_size=0.25,
use_bpl=TRUE,
bpl_max_steps=5,
bpl_epochs_per_step=30,
bpl_dynamic_inc=TRUE,
bpl_balance=FALSE,
bpl_max=1.00,
bpl_anchor=1.00,
bpl_min=0.00,
bpl_weight_inc=0,
bpl_weight_start=1.00,
bpl_model_reset=FALSE,
epochs=20,
batch_size=32,
trace=TRUE,
view_metrics=FALSE,
keras_trace=0,
n_cores=2,
dir_checkpoint="Trial/checkpoints")
#test<-bundle::unbundle(test_classifier2$bundeled_model)
#summary(test)
#set_config_tf_logger("WARN")
#tf$autograph$set_verbosity(0)
test_classifier2$train(#data_embeddings=embeddings_edda_base,
data_embeddings=bert_embeddings,
data_targets=example_targets,
use_baseline=TRUE,
bsl_val_size=0.25,
use_bsc=FALSE,
bsc_methods=c("dbsmote"),
bsc_max_k=10,
bsc_val_size=0.25,
use_bpl=TRUE,
bpl_max_steps=5,
bpl_epochs_per_step=30,
bpl_dynamic_inc=TRUE,
bpl_balance=FALSE,
bpl_max=1.00,
bpl_anchor=1.00,
bpl_min=0.00,
bpl_weight_inc=0,
bpl_weight_start=1.00,
bpl_model_reset=TRUE,
epochs=20,
batch_size=32,
trace=TRUE,
view_metrics=FALSE,
keras_trace=0,
n_cores=2,
dir_checkpoint="Trial/checkpoints")
test_classifier2$reliability$test_metric_mean
#test<-bundle::unbundle(test_classifier2$bundeled_model)
#summary(test)
#set_config_tf_logger("WARN")
#tf$autograph$set_verbosity(0)
test_classifier2$train(#data_embeddings=embeddings_edda_base,
data_embeddings=bert_embeddings,
data_targets=example_targets,
use_baseline=TRUE,
bsl_val_size=0.25,
use_bsc=TRUE,
bsc_methods=c("dbsmote"),
bsc_max_k=10,
bsc_val_size=0.25,
use_bpl=TRUE,
bpl_max_steps=5,
bpl_epochs_per_step=30,
bpl_dynamic_inc=TRUE,
bpl_balance=FALSE,
bpl_max=1.00,
bpl_anchor=1.00,
bpl_min=0.00,
bpl_weight_inc=0,
bpl_weight_start=1.00,
bpl_model_reset=TRUE,
epochs=20,
batch_size=32,
trace=TRUE,
view_metrics=FALSE,
keras_trace=0,
n_cores=2,
dir_checkpoint="Trial/checkpoints")
test_classifier2$reliability$test_metric_mean
test=NULL
for(i in 1:10){
test_classifier2<-TextEmbeddingClassifierNeuralNet$new(
name="Test",
label="abc",
text_embeddings=bert_embeddings,
#text_embeddings=embeddings_edda_base,
targets=example_targets,
#targets=debug_targets,
hidden=c(128,128),
rec=NULL,
self_attention_heads = 0,
dropout=0.5,
l2_regularizer=0.01,
recurrent_dropout=0.4,
optimizer="adam",
act_fct="gelu",
rec_act_fct="tanh")
#test<-bundle::unbundle(test_classifier2$bundeled_model)
#summary(test)
#set_config_tf_logger("WARN")
#tf$autograph$set_verbosity(0)
test_classifier2$train(#data_embeddings=embeddings_edda_base,
data_embeddings=bert_embeddings,
data_targets=example_targets,
use_baseline=TRUE,
bsl_val_size=0.25,
use_bsc=TRUE,
bsc_methods=c("dbsmote"),
bsc_max_k=10,
bsc_val_size=0.25,
use_bpl=TRUE,
bpl_max_steps=5,
bpl_epochs_per_step=30,
bpl_dynamic_inc=TRUE,
bpl_balance=FALSE,
bpl_max=1.00,
bpl_anchor=1.00,
bpl_min=0.00,
bpl_weight_inc=0,
bpl_weight_start=1.00,
bpl_model_reset=TRUE,
epochs=20,
batch_size=32,
trace=TRUE,
view_metrics=FALSE,
keras_trace=0,
n_cores=2,
dir_checkpoint="Trial/checkpoints")
#testtest_classifier2$export_model("Trial/encoder_decoder_modell")
#test_classifier2$import_model("Trial/encoder_decoder_modell")
test[i]=list(test_classifier2$clone(deep=TRUE))
}
#-------------------------------------------------------------------------------
devtools::load_all()
example_data<-data.frame(
id=quanteda::docvars(quanteda.textmodels::data_corpus_moviereviews)$id2,
label=quanteda::docvars(quanteda.textmodels::data_corpus_moviereviews)$sentiment)
example_data$text<-as.character(quanteda.textmodels::data_corpus_moviereviews)
example_data$label[c(1:500,1001:1750)]=NA
example_targets<-as.factor(example_data$label)
names(example_targets)=example_data$id
table(example_targets)
test=NULL
#test<-bundle::unbundle(test_classifier2$bundeled_model)
#summary(test)
#set_config_tf_logger("WARN")
#tf$autograph$set_verbosity(0)
test_classifier2$train(#data_embeddings=embeddings_edda_base,
data_embeddings=bert_embeddings,
data_targets=example_targets,
use_baseline=TRUE,
bsl_val_size=0.25,
use_bsc=TRUE,
bsc_methods=c("dbsmote"),
bsc_max_k=10,
bsc_val_size=0.25,
use_bpl=TRUE,
bpl_max_steps=5,
bpl_epochs_per_step=30,
bpl_dynamic_inc=TRUE,
bpl_balance=FALSE,
bpl_max=1.00,
bpl_anchor=1.00,
bpl_min=0.00,
bpl_weight_inc=0,
bpl_weight_start=1.00,
bpl_model_reset=TRUE,
epochs=20,
batch_size=32,
trace=TRUE,
view_metrics=FALSE,
keras_trace=0,
n_cores=2,
dir_checkpoint="Trial/checkpoints")
for(i in 1:10){
test_classifier2<-TextEmbeddingClassifierNeuralNet$new(
name="Test",
label="abc",
text_embeddings=bert_embeddings,
#text_embeddings=embeddings_edda_base,
targets=example_targets,
#targets=debug_targets,
hidden=c(128,128),
rec=NULL,
self_attention_heads = 0,
dropout=0.5,
l2_regularizer=0.01,
recurrent_dropout=0.4,
optimizer="adam",
act_fct="gelu",
rec_act_fct="tanh")
#test<-bundle::unbundle(test_classifier2$bundeled_model)
#summary(test)
#set_config_tf_logger("WARN")
#tf$autograph$set_verbosity(0)
test_classifier2$train(#data_embeddings=embeddings_edda_base,
data_embeddings=bert_embeddings,
data_targets=example_targets,
use_baseline=TRUE,
bsl_val_size=0.25,
use_bsc=TRUE,
bsc_methods=c("dbsmote"),
bsc_max_k=10,
bsc_val_size=0.25,
use_bpl=TRUE,
bpl_max_steps=5,
bpl_epochs_per_step=30,
bpl_dynamic_inc=TRUE,
bpl_balance=FALSE,
bpl_max=1.00,
bpl_anchor=1.00,
bpl_min=0.00,
bpl_weight_inc=0,
bpl_weight_start=1.00,
bpl_model_reset=TRUE,
epochs=20,
batch_size=32,
trace=TRUE,
view_metrics=FALSE,
keras_trace=0,
n_cores=2,
dir_checkpoint="Trial/checkpoints")
#testtest_classifier2$export_model("Trial/encoder_decoder_modell")
#test_classifier2$import_model("Trial/encoder_decoder_modell")
test[i]=list(test_classifier2$clone(deep=TRUE))
}
test[[1]]$reliability$test_metric_mean
test[[2]]$reliability$test_metric_mean
test[[3]]$reliability$test_metric_mean
for(i in 3:4){
test_classifier2<-TextEmbeddingClassifierNeuralNet$new(
name="Test",
label="abc",
text_embeddings=bert_embeddings,
#text_embeddings=embeddings_edda_base,
targets=example_targets,
#targets=debug_targets,
hidden=c(128,128),
rec=NULL,
self_attention_heads = 0,
dropout=0.5,
l2_regularizer=0.01,
recurrent_dropout=0.4,
optimizer="adam",
act_fct="gelu",
rec_act_fct="tanh")
#test<-bundle::unbundle(test_classifier2$bundeled_model)
#summary(test)
#set_config_tf_logger("WARN")
#tf$autograph$set_verbosity(0)
test_classifier2$train(#data_embeddings=embeddings_edda_base,
data_embeddings=bert_embeddings,
data_targets=example_targets,
use_baseline=TRUE,
bsl_val_size=0.25,
use_bsc=TRUE,
bsc_methods=c("dbsmote"),
bsc_max_k=10,
bsc_val_size=0.25,
use_bpl=TRUE,
bpl_max_steps=5,
bpl_epochs_per_step=30,
bpl_dynamic_inc=TRUE,
bpl_balance=FALSE,
bpl_max=1.00,
bpl_anchor=1.00,
bpl_min=0.00,
bpl_weight_inc=0,
bpl_weight_start=1.00,
bpl_model_reset=TRUE,
epochs=20,
batch_size=32,
trace=TRUE,
view_metrics=FALSE,
keras_trace=0,
n_cores=2,
dir_checkpoint="Trial/checkpoints")
#testtest_classifier2$export_model("Trial/encoder_decoder_modell")
#test_classifier2$import_model("Trial/encoder_decoder_modell")
test[i]=list(test_classifier2$clone(deep=TRUE))
}
test[[3]]$reliability$test_metric_mean
test[[4]]$reliability$test_metric_mean
devtools::check()
library(quanteda.textmodels)
devtools::check()
devtools::document()
devtools::check()
devtools::document()
devtools::document()
devtools::check()
devtools::check()
devto
devtools::document()
?get_synthetic_cases
devtools::load_all()
?get_synthetic_cases
devtools::test()
usethis::use_article(name="abc")
devtools::document()
devtools::test()
load("vignettes/articles/data/bert_embeddings.rda")
devtools::test()
devtools::test()
devtools::test()
load(test_data/basic_text_rep_movie_reviews.rda)
load("test_data/basic_text_rep_movie_reviews.rda")
setwd("~/aifeducation/tests/testthat")
load("test_data/basic_text_rep_movie_reviews.rda")
setwd("~/aifeducation")
devtools::load_all()
devtools::test()
devtools::test()
devtools::test()
devtools::test()
devtools::test()
devtools::test()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::build_site()
gc()
devtools::build_site()
usethis::use_article("test")
devtools::build_site()
devtools::build_site()
devtools::build_site()
devtools::build_site()
.Last.error
devtools::build_site()
devtools::build_site()
devtools::build_site()
.Last.error
devtools::build_site()
devtools::build_site()
devtools::build_site()
devtools::build_site()
devtools::build()
devtools::document()
devtools::build()
devtools::build()
install.packages("~/aifeducation_0.1.0.9000.tar.gz", repos = NULL, type = "source")
devtools::build_site()
devtools::build_site()
devtools::check()
devtools::document()
devtools::check()
setwd("~/aifeducation/tests/testthat")
testthat::skip_on_cran()
testthat::skip_if_not(condition=check_aif_py_modules(trace=FALSE),
message = "Necessary python modules not available")
test_that("train_tune_bert_model", {
example_data<-data.frame(
id=quanteda::docvars(quanteda.textmodels::data_corpus_moviereviews)$id1,
label=quanteda::docvars(quanteda.textmodels::data_corpus_moviereviews)$sentiment)
example_data$text<-as.character(quanteda.textmodels::data_corpus_moviereviews)
expect_no_error(
train_tune_bert_model(output_dir="test_data/tmp",
bert_model_dir_path="test_data/language_models/bert-base-uncased",
raw_texts= example_data$text[1:25],
aug_vocab_by=0,
p_mask=0.30,
whole_word=TRUE,
val_size=0.1,
n_epoch=1,
batch_size=1,
chunk_size=250,
n_workers=1,
multi_process=FALSE,
trace=FALSE))
expect_no_error(
train_tune_bert_model(output_dir="test_data/tmp",
bert_model_dir_path="test_data/language_models/bert-base-uncased",
raw_texts= example_data$text[1:25],
aug_vocab_by=100,
p_mask=0.30,
whole_word=TRUE,
val_size=0.1,
n_epoch=1,
batch_size=1,
chunk_size=250,
n_workers=1,
multi_process=FALSE,
trace=FALSE))
expect_no_error(
train_tune_bert_model(output_dir="test_data/tmp",
bert_model_dir_path="test_data/language_models/bert-base-uncased",
raw_texts= example_data$text[1:25],
aug_vocab_by=0,
p_mask=0.30,
whole_word=FALSE,
val_size=0.1,
n_epoch=1,
batch_size=1,
chunk_size=250,
n_workers=1,
multi_process=FALSE,
trace=FALSE))
})
library(testthat)
test_that("train_tune_bert_model", {
example_data<-data.frame(
id=quanteda::docvars(quanteda.textmodels::data_corpus_moviereviews)$id1,
label=quanteda::docvars(quanteda.textmodels::data_corpus_moviereviews)$sentiment)
example_data$text<-as.character(quanteda.textmodels::data_corpus_moviereviews)
expect_no_error(
train_tune_bert_model(output_dir="test_data/tmp",
bert_model_dir_path="test_data/language_models/bert-base-uncased",
raw_texts= example_data$text[1:25],
aug_vocab_by=0,
p_mask=0.30,
whole_word=TRUE,
val_size=0.1,
n_epoch=1,
batch_size=1,
chunk_size=250,
n_workers=1,
multi_process=FALSE,
trace=FALSE))
expect_no_error(
train_tune_bert_model(output_dir="test_data/tmp",
bert_model_dir_path="test_data/language_models/bert-base-uncased",
raw_texts= example_data$text[1:25],
aug_vocab_by=100,
p_mask=0.30,
whole_word=TRUE,
val_size=0.1,
n_epoch=1,
batch_size=1,
chunk_size=250,
n_workers=1,
multi_process=FALSE,
trace=FALSE))
expect_no_error(
train_tune_bert_model(output_dir="test_data/tmp",
bert_model_dir_path="test_data/language_models/bert-base-uncased",
raw_texts= example_data$text[1:25],
aug_vocab_by=0,
p_mask=0.30,
whole_word=FALSE,
val_size=0.1,
n_epoch=1,
batch_size=1,
chunk_size=250,
n_workers=1,
multi_process=FALSE,
trace=FALSE))
})
devtools::test()
devtools::build()
devtools::check()
devtools::check()
devtools::test()
devtools::test()
print(getwd())
devtools::test()
library(testthat)
tmp_path="test_data/language_models/udpipe_models/english-ewt-ud-2.5-191206.udpipe"
tmp_condition=file.exists(tmp_path)
testthat::skip_if_not(condition=tmp_condition,
message = "udpipe language model not available")
test_that("bow_pp_create_vocab_draft", {
example_data<-data.frame(
id=quanteda::docvars(quanteda.textmodels::data_corpus_moviereviews)$id1,
label=quanteda::docvars(quanteda.textmodels::data_corpus_moviereviews)$sentiment)
example_data$text<-as.character(quanteda.textmodels::data_corpus_moviereviews)
res<-bow_pp_create_vocab_draft(
path_language_model=tmp_path,
data=example_data$text[1:150],
upos=c("NOUN", "ADJ","VERB"),
label_language_model="english-ewt-ud-2.5-191206",
language="english",
chunk_size=50,
trace=FALSE)
expect_type(res,type="list")
})
setwd("C:/Users/WissMit/Documents/aifeducation/tests/testthat")
test_that("bow_pp_create_vocab_draft", {
example_data<-data.frame(
id=quanteda::docvars(quanteda.textmodels::data_corpus_moviereviews)$id1,
label=quanteda::docvars(quanteda.textmodels::data_corpus_moviereviews)$sentiment)
example_data$text<-as.character(quanteda.textmodels::data_corpus_moviereviews)
res<-bow_pp_create_vocab_draft(
path_language_model=tmp_path,
data=example_data$text[1:150],
upos=c("NOUN", "ADJ","VERB"),
label_language_model="english-ewt-ud-2.5-191206",
language="english",
chunk_size=50,
trace=FALSE)
expect_type(res,type="list")
})
devtools::test()
devtools::test()
aifeducation::check_aif_py_modules()
devtools::test()
