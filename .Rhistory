index=1
input=NULL
for(cat in categories){
for(m in 1:length(method)){
if(method[m]!="dbsmote"){
for (k in 2:max_k){
input[[index]]<-list(cat=cat,
k=k,
method=method[m])
index=index+1
}
} else {
input[[index]]<-list(cat=cat,
k=0,
method=method[m])
index=index+1
}
}
}
input
result_list<-foreach(index=1:length(input),.export="create_synthetic_units")%dopar%{
create_synthetic_units(
embedding=embedding,
target=target,
k=input[[index]]$k,
max_k = max_k,
method=input[[index]]$method,
cat=input[[index]]$cat,
cat_freq=cat_freq,
inc_major=inc_major)
}
index=5
k=input[[index]]$k
max_k = max_k
method=input[[index]]$method
cat=input[[index]]$cat
cat_freq=cat_freq
inc_major=inc_major
(cat_freq[cat]!=max(cat_freq) | inc_major==TRUE) &
k<=min(max_k,cat_freq[cat]-1)
tmp_target=(target==cat)
tmp_ration_necessary_cases=sum(tmp_target)/(sum(!tmp_target))
syn_data=NULL
if(method=="smote" & tmp_ration_necessary_cases<1){
syn_data=smotefamily::SMOTE(X=embedding,
target = tmp_target,
K=k,
dup_size = 1)
} else if(method=="adas" & tmp_ration_necessary_cases<1){
syn_data=smotefamily::ADAS(X=embedding,
target = tmp_target,
K=k)
} else if(method=="dbsmote" & tmp_ration_necessary_cases<1){
syn_data=smotefamily::DBSMOTE(X=embedding,
target = tmp_target,
dupSize = 1,
MinPts = NULL,
eps = NULL)
}
syn_data=smotefamily::ADAS(X=embedding,
target = tmp_target,
K=k)
tmp_target
table(tmp_target)
k
syn_data=smotefamily::SMOTE(X=embedding,
target = tmp_target,
K=k,
dup_size = 1)
syn_data=smotefamily::ADAS(X=embedding,
target = tmp_target,
K=k)
syn_data=smotefamily::DBSMOTE(X=embedding,
target = tmp_target,
dupSize = 1,
MinPts = NULL,
eps = NULL)
test_classifier2<-te_classifier_neuralnet$new(
name="Test",
label="abc",
#text_embeddings=embeddings_edda_base,
text_embeddings=embeddings,
targets=as.factor(debug_targets),
config=list(
hidden=c(960,960),
gru=NULL,
dropout=0.2,
l2_regularizer=0.001,
recurrent_dropout=0,
optimizer="adam",
act_fct="sigmoid",
act_fct_last="softmax",
err_fct="CategoricalCrossentropy")
)
test_classifier2$train(data_embeddings=embeddings,
#data_embeddings=embeddings_edda_base,
data_targets=as.factor(debug_targets),
data_n_valid_samples=5,
use_baseline=TRUE,
bsl_val_size=0.25,
use_bsc=TRUE,
bsc_methods=c("smote"),
bsc_max_k=5,
use_bpl=TRUE,
bpl_max_steps=6,
bpl_inc_ratio=0.5,
bpl_anchor=0.66,
bpl_valid_size=0.33,
epochs=30,
batch_size=32,
trace=TRUE,
keras_trace=1,
view_metrics=FALSE,
n_cores=1,
dir_checkpoint="Trial/checkpoints",
opt_model_reset=TRUE)
tf=reticulate::import("tensorflow")
#-------------------------------------------------------------------------------
devtools::load_all()
test_classifier2<-te_classifier_neuralnet$new(
name="Test",
label="abc",
#text_embeddings=embeddings_edda_base,
text_embeddings=embeddings,
targets=as.factor(debug_targets),
config=list(
hidden=c(960,960),
gru=NULL,
dropout=0.2,
l2_regularizer=0.001,
recurrent_dropout=0,
optimizer="adam",
act_fct="sigmoid",
act_fct_last="softmax",
err_fct="CategoricalCrossentropy")
)
test_classifier2$train(data_embeddings=embeddings,
#data_embeddings=embeddings_edda_base,
data_targets=as.factor(debug_targets),
data_n_valid_samples=2,
use_baseline=TRUE,
bsl_val_size=0.25,
use_bsc=FALSE,
bsc_methods=c("smote"),
bsc_max_k=5,
use_bpl=FALSE,
bpl_max_steps=6,
bpl_inc_ratio=0.5,
bpl_anchor=0.66,
bpl_valid_size=0.33,
epochs=30,
batch_size=32,
trace=TRUE,
keras_trace=1,
view_metrics=FALSE,
n_cores=1,
dir_checkpoint="Trial/checkpoints",
opt_model_reset=TRUE)
test_classifier2$reliability$val_metric_mean
test_classifier2$export_model("Trial/encoder_decoder_modell")
#-------------------------------------------------------------------------------
devtools::load_all()
test_classifier2<-te_classifier_neuralnet$new(
name="Test",
label="abc",
#text_embeddings=embeddings_edda_base,
text_embeddings=embeddings,
targets=as.factor(debug_targets),
config=list(
hidden=c(960,960),
gru=NULL,
dropout=0.2,
l2_regularizer=0.001,
recurrent_dropout=0,
optimizer="adam",
act_fct="sigmoid",
act_fct_last="softmax",
err_fct="CategoricalCrossentropy")
)
test_classifier2$train(data_embeddings=embeddings,
#data_embeddings=embeddings_edda_base,
data_targets=as.factor(debug_targets),
data_n_valid_samples=2,
use_baseline=TRUE,
bsl_val_size=0.25,
use_bsc=FALSE,
bsc_methods=c("smote"),
bsc_max_k=5,
use_bpl=FALSE,
bpl_max_steps=6,
bpl_inc_ratio=0.5,
bpl_anchor=0.66,
bpl_valid_size=0.33,
epochs=30,
batch_size=32,
trace=TRUE,
keras_trace=1,
view_metrics=FALSE,
n_cores=1,
dir_checkpoint="Trial/checkpoints",
opt_model_reset=TRUE)
test_classifier2$export_model("Trial/encoder_decoder_modell")
test_classifier2$export_model("Trial/encoder_decoder_modell")
res<-test_classifier2$predict(embedding)
table(res$expected_category)
table(res$expected_category,debug_targets)
table(cbind(res$expected_category,debug_targets))
table(as.data.frame(cbind(res$expected_category,debug_targets)))
#-------------------------------------------------------------------------------
devtools::load_all()
test_classifier2<-te_classifier_neuralnet$new(
name="Test",
label="abc",
#text_embeddings=embeddings_edda_base,
text_embeddings=embeddings,
targets=as.factor(debug_targets),
config=list(
hidden=c(960,960),
gru=NULL,
dropout=0.2,
l2_regularizer=0.001,
recurrent_dropout=0,
optimizer="adam",
act_fct="sigmoid",
act_fct_last="softmax",
err_fct="CategoricalCrossentropy")
)
test_classifier2$train(data_embeddings=embeddings,
#data_embeddings=embeddings_edda_base,
data_targets=as.factor(debug_targets),
data_n_valid_samples=2,
use_baseline=TRUE,
bsl_val_size=0.25,
use_bsc=FALSE,
bsc_methods=c("smote"),
bsc_max_k=5,
use_bpl=FALSE,
bpl_max_steps=6,
bpl_inc_ratio=0.5,
bpl_anchor=0.66,
bpl_valid_size=0.33,
epochs=30,
batch_size=32,
trace=TRUE,
keras_trace=1,
view_metrics=FALSE,
n_cores=1,
dir_checkpoint="Trial/checkpoints",
opt_model_reset=TRUE)
test_classifier2$export_model("Trial/encoder_decoder_modell")
test<-bundle::unbundle(test_classifier2$bundeled_model)
#-------------------------------------------------------------------------------
devtools::load_all()
test_classifier2<-te_classifier_neuralnet$new(
name="Test",
label="abc",
#text_embeddings=embeddings_edda_base,
text_embeddings=embeddings,
targets=as.factor(debug_targets),
config=list(
hidden=c(960,960),
gru=NULL,
dropout=0.2,
l2_regularizer=0.001,
recurrent_dropout=0,
optimizer="adam",
act_fct="sigmoid",
act_fct_last="softmax",
err_fct="CategoricalCrossentropy")
)
test_classifier2$train(data_embeddings=embeddings,
#data_embeddings=embeddings_edda_base,
data_targets=as.factor(debug_targets),
data_n_valid_samples=2,
use_baseline=TRUE,
bsl_val_size=0.25,
use_bsc=FALSE,
bsc_methods=c("smote"),
bsc_max_k=5,
use_bpl=FALSE,
bpl_max_steps=6,
bpl_inc_ratio=0.5,
bpl_anchor=0.66,
bpl_valid_size=0.33,
epochs=30,
batch_size=32,
trace=TRUE,
keras_trace=1,
view_metrics=FALSE,
n_cores=1,
dir_checkpoint="Trial/checkpoints",
opt_model_reset=TRUE)
test_classifier2$export_model("Trial/encoder_decoder_modell")
test_classifier2$import_model("Trial/encoder_decoder_modell")
#-------------------------------------------------------------------------------
devtools::load_all()
test_classifier2<-te_classifier_neuralnet$new(
name="Test",
label="abc",
#text_embeddings=embeddings_edda_base,
text_embeddings=embeddings,
targets=as.factor(debug_targets),
config=list(
hidden=c(960,960),
gru=NULL,
dropout=0.2,
l2_regularizer=0.001,
recurrent_dropout=0,
optimizer="adam",
act_fct="sigmoid",
act_fct_last="softmax",
err_fct="CategoricalCrossentropy")
)
test_classifier2$train(data_embeddings=embeddings,
#data_embeddings=embeddings_edda_base,
data_targets=as.factor(debug_targets),
data_n_valid_samples=2,
use_baseline=TRUE,
bsl_val_size=0.25,
use_bsc=FALSE,
bsc_methods=c("smote"),
bsc_max_k=5,
use_bpl=FALSE,
bpl_max_steps=6,
bpl_inc_ratio=0.5,
bpl_anchor=0.66,
bpl_valid_size=0.33,
epochs=30,
batch_size=32,
trace=TRUE,
keras_trace=1,
view_metrics=FALSE,
n_cores=1,
dir_checkpoint="Trial/checkpoints",
opt_model_reset=TRUE)
test_classifier2$export_model("Trial/encoder_decoder_modell")
test_classifier2$import_model("Trial/encoder_decoder_modell")
res<-test_classifier2$predict(embedding)
table(as.data.frame(cbind(res$expected_category,debug_targets)))
table(as.data.frame((res$expected_category,debug_targets))
table(as.data.frame(c(res$expected_category,debug_targets))
table(as.data.frame(c(res$expected_category,debug_targets)))
table(as.data.frame(cbind(res$expected_category,debug_targets[names(res$expected_category)])))
table(as.data.frame(cbind(res$expected_category,debug_targets[names(res$expected_category)])))
cbind(res$expected_category,debug_targets[names(res$expected_category)])
names(res$expected_category)
table(as.data.frame(cbind(res$expected_category,debug_targets[rownames(res$expected_category)])))
table(as.data.frame(cbind(res$expected_category,debug_targets[rownames(res)])))
table(as.data.frame(cbind(pred=res$expected_category,true=debug_targets[rownames(res)])))
test_classifier2$train(data_embeddings=embeddings,
#data_embeddings=embeddings_edda_base,
data_targets=as.factor(debug_targets),
data_n_valid_samples=2,
use_baseline=TRUE,
bsl_val_size=0.25,
use_bsc=TRUE,
bsc_methods=c("smote"),
bsc_max_k=5,
use_bpl=FALSE,
bpl_max_steps=6,
bpl_inc_ratio=0.5,
bpl_anchor=0.66,
bpl_valid_size=0.33,
epochs=30,
batch_size=32,
trace=TRUE,
keras_trace=1,
view_metrics=FALSE,
n_cores=4,
dir_checkpoint="Trial/checkpoints",
opt_model_reset=TRUE)
res<-test_classifier2$predict(embedding)
table(as.data.frame(cbind(pred=res$expected_category,true=debug_targets[rownames(res)])))
test_classifier2$reliability$val_metric_mean
res<-test_classifier2$predict(embedding)
table(as.data.frame(cbind(pred=res$expected_category,true=debug_targets[rownames(res)])))
test_classifier2$reliability$val_metric_mean
test_classifier2$train(data_embeddings=embeddings,
#data_embeddings=embeddings_edda_base,
data_targets=as.factor(debug_targets),
data_n_valid_samples=2,
use_baseline=TRUE,
bsl_val_size=0.25,
use_bsc=TRUE,
bsc_methods=c("dbsmote"),
bsc_max_k=5,
use_bpl=FALSE,
bpl_max_steps=6,
bpl_inc_ratio=0.5,
bpl_anchor=0.66,
bpl_valid_size=0.33,
epochs=30,
batch_size=32,
trace=TRUE,
keras_trace=1,
view_metrics=FALSE,
n_cores=4,
dir_checkpoint="Trial/checkpoints",
opt_model_reset=TRUE)
res<-test_classifier2$predict(embedding)
table(as.data.frame(cbind(pred=res$expected_category,true=debug_targets[rownames(res)])))
test_classifier2$reliability$val_metric_mean
training_data$mot_prob
abc<-training_data$mot_prob
tmp_target<-training_data$mot_prob
test<-table(abc)
test
test<-subset(test,test<3)
test
test==0
tmp_target<-training_data$mot_prob
tmp_target_table<-table(abc)
for(i in 1:length(tmp_target_table)){
if(tmp_target_table[i]<4){
tmp_target_table[tmp_target_table==names(tmp_target_table)[i]]=NA
}
}
table(tmp_target)
tmp_target<-training_data$mot_prob
tmp_target_table<-table(abc)
for(i in 1:length(tmp_target_table)){
if(tmp_target_table[i]<5){
tmp_target[tmp_target==names(tmp_target_table)[i]]=NA
}
}
table(tmp_target)
devtools::document()
?TextEmbeddingModel
devtools::document()
?TextEmbeddingModel
?TextEmbeddingModel
devtools::document()
?TextEmbeddingModel
devtools::document()
?TextEmbeddingModel
#load("C:/Users/WissMit/Desktop/Forschung Hamburg/KI und Unterrichtsentwuerfe/Trainingscenter/Output/Embeddings/gbert_base/embeddings_gbert_base.RData")
load("C:/Users/WissMit/Desktop/Forschung Hamburg/KI und Unterrichtsentwuerfe/Trainingscenter/Output/Embeddings/embeddings_edda_gvc_96_10.RData")
load("C:/Users/WissMit/Desktop/Forschung Hamburg/KI und Unterrichtsentwuerfe/Trainingscenter/Output/Text_Embedding_Models/edda_gvc_96_10.RData")
abc<-edda_gvc_96_10$tokenize("Dies ist ein Test.")
abc
text_embedding_model<-TextEmbeddingModel$new(model_name="German Bert Large",
method = "bert",
#bert_model="deepset/gbert-large",
bert_model_dir_path="Trial/Bert_Modelle/",
model_version = "0.0.1",
model_language = "german",
max_length = 250,
chunks = 8,
overlap=50,
aggregation = "fourth_to_last",
aggregate_cls = FALSE,
trace=TRUE)
text_embedding_model<-TextEmbeddingModel$new(model_name="German Bert Large",
method = "bert",
#bert_model="deepset/gbert-large",
bert_model_dir_path="Trial/Bert_Modelle/",
model_version = "0.0.1",
model_language = "german",
max_length = 250,
chunks = 8,
overlap=50,
aggregation = "fourth_to_last",
use_cls = FALSE,
trace=TRUE)
text_embedding_model<-TextEmbeddingModel$new(model_name="German Bert Large",
model_label="Test",
method = "bert",
#bert_model="deepset/gbert-large",
bert_model_dir_path="Trial/Bert_Modelle/",
model_version = "0.0.1",
model_language = "german",
max_length = 250,
chunks = 8,
overlap=50,
aggregation = "fourth_to_last",
use_cls = FALSE,
trace=TRUE)
abc<-text_embedding_model$tokenize("dies ist ein Test")
abc
abc[[1]]
abc[[1]][[1]]
abc[[1]][[1]][1]
abc[[1]][[1]][[1]]
abc[[1]][[1]]
abc[[1]][[1]]["input_ids"]
as.vector(abc[[1]][[1]]["input_ids"])
devtools::load_all()
text_embedding_model<-TextEmbeddingModel$new(model_name="German Bert Large",
model_label="Test",
method = "bert",
#bert_model="deepset/gbert-large",
bert_model_dir_path="Trial/Bert_Modelle/",
model_version = "0.0.1",
model_language = "german",
max_length = 250,
chunks = 8,
overlap=50,
aggregation = "fourth_to_last",
use_cls = FALSE,
trace=TRUE)
abc<-text_embedding_model$encode("dies ist ein Test","Schüler sollten mehr lernen.")
abc
abc<-text_embedding_model$encode(c("dies ist ein Test","Schüler sollten mehr lernen."),
token_encodings_only = FALSE)
abc
abc<-text_embedding_model$encode(c("dies ist ein Test","Schüler sollten mehr lernen."),
token_encodings_only = TRUE)
abc
devtools::document()
?TextEmbeddingModel
devtools::document()
?TextEmbeddingModel
