sizes[cat]
selected_names=sample(x=possible_names,
size=length(possible_names))
selected_names
selected_names=sample(x=possible_names,
size=min(length(possible_names),
sizes))
selected_names
val_sample=NULL
sizes=min(ceiling(freq_cat/fin_k_folds),1)
for(i in 1:fin_k_folds){
for(cat in categories){
all_names=names(subset(target,target==cat))
if(is.null(val_sample)==TRUE){
possible_names=all_names
} else {
possible_names=setdiff(x=all_names,
y=unlist(val_sample))
}
selected_names=sample(x=possible_names,
size=min(length(possible_names),
sizes))
val_sample[i]=list(append(x=unlist(val_sample[i]),
values = selected_names))
}
}
val_sample
target
sample_target=na.omit(target)
freq_cat=table(sample_target)
categories=names(freq_cat)
min_freq=min(freq_cat)
freq_cat
if(min_freq/k_folds<4){
fin_k_folds=floor(min_freq/4)
warning(paste("Frequency of the smallest category/label is not sufficent to ensure
at least 4 cases per fold. Adjusting number of folds from ",k_folds,"to",fin_k_folds,"."))
if(fin_k_folds==0){
stop("Frequency of the smallest category/label is to low. Please check your data.
Consider to remove all categories/labels with a very low absolute frequency.")
}
} else {
fin_k_folds=k_folds
}
val_sample=NULL
sizes=min(ceiling(freq_cat/fin_k_folds),1)
for(i in 1:fin_k_folds){
for(cat in categories){
all_names=names(subset(target,target==cat))
if(is.null(val_sample)==TRUE){
possible_names=all_names
} else {
possible_names=setdiff(x=all_names,
y=unlist(val_sample))
}
selected_names=sample(x=possible_names,
size=min(length(possible_names),
sizes))
val_sample[i]=list(append(x=unlist(val_sample[i]),
values = selected_names))
}
}
val_sample
categories
val_sample=NULL
sizes=min(ceiling(freq_cat/fin_k_folds),1)
for(i in 1:fin_k_folds){
for(cat in categories){
all_names=names(subset(target,target==cat))
if(is.null(val_sample)==TRUE){
possible_names=all_names
} else {
possible_names=setdiff(x=all_names,
y=unlist(val_sample))
}
selected_names=sample(x=possible_names,
size=min(length(possible_names),
sizes))
val_sample[i]=list(append(x=unlist(val_sample[i]),
values = selected_names))
}
}
freq_cat
val_sample=NULL
for(i in 1:fin_k_folds){
for(cat in categories){
all_names=names(subset(target,target==cat))
sizes=min(ceiling(freq_cat[cat]/fin_k_folds),1)
if(is.null(val_sample)==TRUE){
possible_names=all_names
} else {
possible_names=setdiff(x=all_names,
y=unlist(val_sample))
}
selected_names=sample(x=possible_names,
size=min(length(possible_names),
sizes))
val_sample[i]=list(append(x=unlist(val_sample[i]),
values = selected_names))
}
}
val_sample
sizes
val_sample=NULL
for(i in 1:fin_k_folds){
for(cat in categories){
all_names=names(subset(target,target==cat))
sizes=max(ceiling(freq_cat[cat]/fin_k_folds),1)
if(is.null(val_sample)==TRUE){
possible_names=all_names
} else {
possible_names=setdiff(x=all_names,
y=unlist(val_sample))
}
selected_names=sample(x=possible_names,
size=min(length(possible_names),
sizes))
val_sample[i]=list(append(x=unlist(val_sample[i]),
values = selected_names))
}
}
val_sample
table(target[val_sample[[1]]])
table(target[val_sample[[2]]])
train_sample=NULL
for(i in 1:fin_k_folds){
train_sample[i]=list(setdiff(x=names(sample_target),y=val_sample[[i]]))
}
table(target[val_sample[[2]]])
table(target[train_sample[[2]]])
#-------------------------------------------------------------------------------
devtools::load_all()
test_classifier2<-TextEmbeddingClassifierNeuralNet$new(
name="Test",
label="abc",
text_embeddings=embeddings_edda_base,
#text_embeddings=embeddings,
targets=as.factor(debug_targets),
config=list(
hidden=NULL,
gru=c(64),
dropout=0.2,
l2_regularizer=0.001,
recurrent_dropout=0,
optimizer="adam",
act_fct="sigmoid",
act_fct_last="softmax",
err_fct="CategoricalCrossentropy")
)
test<-bundle::unbundle(test_classifier2$bundeled_model)
summary(test)
test_classifier2$train(#data_embeddings=embeddings,
data_embeddings=embeddings_edda_base,
data_targets=as.factor(debug_targets),
data_n_valid_samples=5,
use_baseline=TRUE,
bsl_val_size=0.25,
use_bsc=TRUE,
bsc_methods=c("dbsmote"),
bsc_max_k=5,
use_bpl=FALSE,
bpl_max_steps=6,
bpl_inc_ratio=0.5,
bpl_anchor=0.66,
bpl_valid_size=0.33,
epochs=30,
batch_size=32,
trace=TRUE,
keras_trace=1,
view_metrics=FALSE,
n_cores=4,
dir_checkpoint="Trial/checkpoints",
opt_model_reset=TRUE)
#-------------------------------------------------------------------------------
devtools::load_all()
test_classifier2<-TextEmbeddingClassifierNeuralNet$new(
name="Test",
label="abc",
text_embeddings=embeddings_edda_base,
#text_embeddings=embeddings,
targets=as.factor(debug_targets),
config=list(
hidden=NULL,
gru=c(64),
dropout=0.2,
l2_regularizer=0.001,
recurrent_dropout=0,
optimizer="adam",
act_fct="sigmoid",
act_fct_last="softmax",
err_fct="CategoricalCrossentropy")
)
test<-bundle::unbundle(test_classifier2$bundeled_model)
summary(test)
test_classifier2$train(#data_embeddings=embeddings,
data_embeddings=embeddings_edda_base,
data_targets=as.factor(debug_targets),
data_n_valid_samples=5,
use_baseline=TRUE,
bsl_val_size=0.25,
use_bsc=TRUE,
bsc_methods=c("dbsmote"),
bsc_max_k=5,
use_bpl=FALSE,
bpl_max_steps=6,
bpl_inc_ratio=0.5,
bpl_anchor=0.66,
bpl_valid_size=0.33,
epochs=30,
batch_size=32,
trace=TRUE,
keras_trace=1,
view_metrics=FALSE,
n_cores=4,
dir_checkpoint="Trial/checkpoints",
opt_model_reset=TRUE)
devtools::build()
devtools::load_all()
load("C:/Users/WissMit/Desktop/Forschung Hamburg/KI und Unterrichtsentwuerfe/Trainingscenter/Output/sources/Training_Data.RData")
load("C:/Users/WissMit/Desktop/Forschung Hamburg/KI und Unterrichtsentwuerfe/Trainingscenter/Output/Embeddings/gbert_base/embeddings_gbert_base.RData")
debug_targets<-training_data$operate
names(debug_targets)=training_data$doc_id
debug_targets<-as.factor(debug_targets)
table(debug_targets)
#-------------------------------------------------------------------------------
devtools::load_all()
test_classifier2<-TextEmbeddingClassifierNeuralNet$new(
name="Test",
label="abc",
text_embeddings=embeddings_edda_base,
#text_embeddings=embeddings,
targets=as.factor(debug_targets),
config=list(
hidden=NULL,
gru=c(64),
dropout=0.2,
l2_regularizer=0.001,
recurrent_dropout=0,
optimizer="adam",
act_fct="sigmoid",
act_fct_last="softmax",
err_fct="CategoricalCrossentropy")
)
test<-bundle::unbundle(test_classifier2$bundeled_model)
summary(test)
test_classifier2$train(#data_embeddings=embeddings,
data_embeddings=embeddings_edda_base,
data_targets=as.factor(debug_targets),
data_n_valid_samples=5,
use_baseline=TRUE,
bsl_val_size=0.25,
use_bsc=TRUE,
bsc_methods=c("dbsmote"),
bsc_max_k=5,
use_bpl=FALSE,
bpl_max_steps=6,
bpl_inc_ratio=0.5,
bpl_anchor=0.66,
bpl_valid_size=0.33,
epochs=30,
batch_size=32,
trace=TRUE,
keras_trace=1,
view_metrics=FALSE,
n_cores=4,
dir_checkpoint="Trial/checkpoints",
opt_model_reset=TRUE)
devtools::build()
devtools::document()
?check_embedding_models
devtools::document()
?check_embedding_models
devtools::document()
?create_iota2_mean_object
devtools::document()
?create_iota2_mean_object
devtools::document()
?create_iota2_mean_object
?get_synthetic_cases
devtools::document()
?get_stratified_train_test_split
devtools::document()
?get_stratified_train_test_split
devtools::document()
?bow_pp_create_vocab_draft
devtools::document()
?bow_pp_create_vocab_draft
devtools::document()
?bow_pp_create_vocab_draft
devtools::document()
?bow_pp_create_basic_text_rep
devtools::document()
?bow_pp_create_basic_text_rep
devtools::document()
?bow_pp_create_basic_text_rep
devtools::document()
?matrix_to_array_c
devtools::document()
devtools::document()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::check()
devtools::document()
?TExtEmbeddingClassifierNeuralNet
devtools::document()
?TExtEmbeddingClassifierNeuralNet
devtools::document()
?TExtEmbeddingClassifierNeuralNet
devtools::document()
?TExtEmbeddingClassifierNeuralNet
devtools::check()
devtools::document()
?TExtEmbeddingClassifierNeuralNet
devtools::document()
?TExtEmbeddingClassifierNeuralNet
devtools::check()
devtools::check()
devtools::document()
?TextEmbeddingModel
devtools::check()
devtools::check()
devtools::document()
?QAExtractModel
devtools::document()
?QAExtractModel
devtools::document()
?QAExtractModel
devtools::document()
devtools::document()
devtools::document()
?QAExtractModel
devtools::document()
devtools::check()
devtools::build_manual()
devtools::build()
check_aif_py_modules(){
check_aif_py_modules<-function(){
relevant_modules<-c("os",
"transformers",
"tokenizers",
"datasets",
"torch",
"keras",
"tensorflow")
matrix_overview=matrix(data=NA,
nrow = length(relevant_modules),
ncol= 2)
colnames(matrix_overview)=c("module","available")
for(i in 1:length(relevant_modules)){
matrix_overview[i,1]<-relevant_modules[i]
matrix_overview[i,2]<-reticulate::py_module_available(relevant_modules[i])
}
}
check_aif_py_modules<-function(){
relevant_modules<-c("os",
"transformers",
"tokenizers",
"datasets",
"torch",
"keras",
"tensorflow")
matrix_overview=matrix(data=NA,
nrow = length(relevant_modules),
ncol= 2)
colnames(matrix_overview)=c("module","available")
for(i in 1:length(relevant_modules)){
matrix_overview[i,1]<-relevant_modules[i]
matrix_overview[i,2]<-reticulate::py_module_available(relevant_modules[i])
}
print(matrix_overview)
if(Sum(matrix_overview[,2])==length(relevant_modules)){
return(TRUE)
} else {
return(FALSE)
}
}
check_aif_py_modules()
check_aif_py_modules<-function(){
relevant_modules<-c("os",
"transformers",
"tokenizers",
"datasets",
"torch",
"keras",
"tensorflow")
matrix_overview=matrix(data=NA,
nrow = length(relevant_modules),
ncol= 2)
colnames(matrix_overview)=c("module","available")
for(i in 1:length(relevant_modules)){
matrix_overview[i,1]<-relevant_modules[i]
matrix_overview[i,2]<-reticulate::py_module_available(relevant_modules[i])
}
print(matrix_overview)
if(sum(matrix_overview[,2])==length(relevant_modules)){
return(TRUE)
} else {
return(FALSE)
}
}
check_aif_py_modules()
check_aif_py_modules<-function(){
relevant_modules<-c("os",
"transformers",
"tokenizers",
"datasets",
"torch",
"keras",
"tensorflow")
matrix_overview=matrix(data=NA,
nrow = length(relevant_modules),
ncol= 2)
colnames(matrix_overview)=c("module","available")
for(i in 1:length(relevant_modules)){
matrix_overview[i,1]<-relevant_modules[i]
matrix_overview[i,2]<-reticulate::py_module_available(relevant_modules[i])
}
print(matrix_overview)
if(sum(as.numeric(matrix_overview[,2]))==length(relevant_modules)){
return(TRUE)
} else {
return(FALSE)
}
}
check_aif_py_modules()
relevant_modules<-c("os",
"transformers",
"tokenizers",
"datasets",
"torch",
"keras",
"tensorflow")
matrix_overview=matrix(data=NA,
nrow = length(relevant_modules),
ncol= 2)
colnames(matrix_overview)=c("module","available")
for(i in 1:length(relevant_modules)){
matrix_overview[i,1]<-relevant_modules[i]
matrix_overview[i,2]<-reticulate::py_module_available(relevant_modules[i])
}
print(matrix_overview)
as.numeric(matrix_overview[,2])
as.numeric(as.character(matrix_overview[,2])))
as.character(matrix_overview[,2])
as.numeric(as.character(matrix_overview[,2])))
matrix_overview<-as.data.frame(matrix_overview)
matrix_overview=matrix(data=NA,
nrow = length(relevant_modules),
ncol= 2)
colnames(matrix_overview)=c("module","available")
matrix_overview<-as.data.frame(matrix_overview)
for(i in 1:length(relevant_modules)){
matrix_overview[i,1]<-relevant_modules[i]
matrix_overview[i,2]<-reticulate::py_module_available(relevant_modules[i])
}
print(matrix_overview)
if(sum(matrix_overview[,2]))==length(relevant_modules)){
print(matrix_overview)
if(sum(matrix_overview[,2])==length(relevant_modules)){
return(TRUE)
} else {
return(FALSE)
}
sum(matrix_overview[,2]
)
check_aif_py_modules<-function(){
relevant_modules<-c("os",
"transformers",
"tokenizers",
"datasets",
"torch",
"keras",
"tensorflow")
matrix_overview=matrix(data=NA,
nrow = length(relevant_modules),
ncol= 2)
colnames(matrix_overview)=c("module","available")
matrix_overview<-as.data.frame(matrix_overview)
for(i in 1:length(relevant_modules)){
matrix_overview[i,1]<-relevant_modules[i]
matrix_overview[i,2]<-reticulate::py_module_available(relevant_modules[i])
}
print(matrix_overview)
if(sum(matrix_overview[,2])==length(relevant_modules)){
return(TRUE)
} else {
return(FALSE)
}
}
check_aif_py_modules()
devtools::document()
devtools::load_all()
rm(list = c("check_aif_py_modules"))
devtools::load_all()
devtools::load_all()
tf
tf$
devtools::load_all()
#Creating a new Tokenizer for Computing Vocabulary
tok_new<-tok$Tokenizer(tok$models$WordPiece())
devtools::load_all()
#Creating a new Tokenizer for Computing Vocabulary
tok_new<-tok$Tokenizer(tok$models$WordPiece())
reticulate::py_available()
reticulate::py_config()
#Creating a new Tokenizer for Computing Vocabulary
tok_new<-tok$Tokenizer(tok$models$WordPiece())
devtools::load_all()
