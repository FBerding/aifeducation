classifier_with_fe$train(
data_embeddings = review_embeddings,
data_targets = review_labels,
data_folds = 10,
data_val_size = 0.25,
loss_balance_class_weights = TRUE,
loss_balance_sequence_length = TRUE,
loss_cls_fct_name="FocalLoss",
use_sc = FALSE,
sc_method = "knnor",
sc_min_k = 1,
sc_max_k = 10,
use_pl = FALSE,
pl_max_steps = 3,
pl_max = 1.00,
pl_anchor = 1.00,
pl_min = 0.00,
sustain_track = TRUE,
sustain_iso_code = "DEU",
sustain_region = NULL,
sustain_interval = 15,
epochs = 150,
batch_size = 32,
trace = TRUE,
ml_trace = 0,
log_dir = NULL,
log_write_interval = 10,
n_cores = auto_n_cores(),
lr_rate=1e-3,
lr_warm_up_ratio=0.02,
optimizer="adamw"
)
classifier_with_fe$reliability$test_metric_mean
classifier_with_fe <- TEClassifierSequential$new()
classifier_with_fe$configure(
label = "Classifier for Estimating a Postive or Negative Rating of Movie Reviews",
text_embeddings = review_embeddings,
feature_extractor = feature_extractor,
target_levels = c("neg", "pos"),
skip_connection_type="residual_gate",
cls_pooling_features=30,
cls_pooling_type="min_max",
feat_act_fct="elu",
feat_size=64,
feat_bias=TRUE,
feat_dropout=0.0,
feat_parametrizations="None",
feat_normalization_type="layer_norm",
ng_conv_act_fct="elu",
ng_conv_n_layers=0,
ng_conv_ks_min=2,
ng_conv_ks_max=4,
ng_conv_bias=FALSE,
ng_conv_dropout=0.1,
ng_conv_parametrizations="None",
ng_conv_normalization_type="layer_norm",
ng_conv_residual_type="residual_gate",
dense_act_fct="elu",
dense_n_layers=1,
dense_dropout=0.5,
dense_bias=FALSE,
dense_parametrizations="None",
dense_normalization_type="layer_norm",
dense_residual_type="residual_gate",
rec_act_fct="tanh",
rec_n_layers=2,
rec_type="gru",
rec_bidirectional=FALSE,
rec_dropout=0.2,
rec_bias=FALSE,
rec_parametrizations="None",
rec_normalization_type="layer_norm",
rec_residual_type="residual_gate",
tf_act_fct="elu",
tf_dense_dim=512,
tf_n_layers=0,
tf_dropout_rate_1=0.2,
tf_dropout_rate_2=0.5,
tf_attention_type="multihead",
tf_embedding_type="absolute",
tf_num_heads=1,
tf_bias=FALSE,
tf_parametrizations="None",
tf_normalization_type="layer_norm",
tf_residual_type="residual_gate"
)
classifier_with_fe$train(
data_embeddings = review_embeddings,
data_targets = review_labels,
data_folds = 10,
data_val_size = 0.25,
loss_balance_class_weights = TRUE,
loss_balance_sequence_length = TRUE,
loss_cls_fct_name="FocalLoss",
use_sc = FALSE,
sc_method = "knnor",
sc_min_k = 1,
sc_max_k = 10,
use_pl = FALSE,
pl_max_steps = 3,
pl_max = 1.00,
pl_anchor = 1.00,
pl_min = 0.00,
sustain_track = TRUE,
sustain_iso_code = "DEU",
sustain_region = NULL,
sustain_interval = 15,
epochs = 150,
batch_size = 32,
trace = TRUE,
ml_trace = 0,
log_dir = NULL,
log_write_interval = 10,
n_cores = auto_n_cores(),
lr_rate=1e-3,
lr_warm_up_ratio=0.02,
optimizer="adamw"
)
classifier_with_fe$reliability$test_metric_mean
768*0.75
devtools::load_all()
build_aife_site()
new_predictions=classifier_prototype$predict_with_samples(
newdata = query_embeddings,
embeddings_s = sample_embeddings,
classes_s = sample_classes
)
head(new_predictions)
table(new_predictions$expected_category)
# If your classifier is not loaded
classifier <- load_from_disk("examples/cls_imdb_movie_reviews")
# Predict the classes of new texts
predicted_categories <- classifier$predict(
newdata = review_embeddings,
batch_size = 8
)
# Show predicted categories
head(predicted_categories)
feature_extractor <- TEFeatureExtractor$new()
feature_extractor$configure(
name = "feature_extractor_bert_movie_reviews",
label = "Feature extractor for Text Embeddings via BERT",
text_embeddings = review_embeddings,
features = 576,
method = "dense",
noise_factor = 0.2
)
feature_extractor$train(
data_embeddings = review_embeddings,
data_val_size = 0.25,
sustain_track = TRUE,
sustain_iso_code = "DEU",
sustain_region = NULL,
sustain_interval = 15,
epochs = 500,
batch_size = 32,
trace = TRUE,
ml_trace = 0,
optimizer = "adamw"
)
feature_extractor$plot_training_history()
classifier_with_fe <- TEClassifierSequential$new()
classifier_with_fe$configure(
label = "Classifier for Estimating a Postive or Negative Rating of Movie Reviews",
text_embeddings = review_embeddings,
feature_extractor = feature_extractor,
target_levels = c("neg", "pos"),
skip_connection_type="residual_gate",
cls_pooling_features=50,
cls_pooling_type="min_max",
feat_act_fct="elu",
feat_size=256,
feat_bias=TRUE,
feat_dropout=0.0,
feat_parametrizations="None",
feat_normalization_type="layer_norm",
ng_conv_act_fct="elu",
ng_conv_n_layers=0,
ng_conv_ks_min=2,
ng_conv_ks_max=4,
ng_conv_bias=FALSE,
ng_conv_dropout=0.1,
ng_conv_parametrizations="None",
ng_conv_normalization_type="layer_norm",
ng_conv_residual_type="residual_gate",
dense_act_fct="elu",
dense_n_layers=1,
dense_dropout=0.5,
dense_bias=FALSE,
dense_parametrizations="None",
dense_normalization_type="layer_norm",
dense_residual_type="residual_gate",
rec_act_fct="tanh",
rec_n_layers=2,
rec_type="gru",
rec_bidirectional=FALSE,
rec_dropout=0.2,
rec_bias=FALSE,
rec_parametrizations="None",
rec_normalization_type="layer_norm",
rec_residual_type="residual_gate",
tf_act_fct="elu",
tf_dense_dim=512,
tf_n_layers=0,
tf_dropout_rate_1=0.2,
tf_dropout_rate_2=0.5,
tf_attention_type="multihead",
tf_embedding_type="absolute",
tf_num_heads=1,
tf_bias=FALSE,
tf_parametrizations="None",
tf_normalization_type="layer_norm",
tf_residual_type="residual_gate"
)
classifier_with_fe$train(
data_embeddings = review_embeddings,
data_targets = review_labels,
data_folds = 10,
data_val_size = 0.25,
loss_balance_class_weights = TRUE,
loss_balance_sequence_length = TRUE,
loss_cls_fct_name="FocalLoss",
use_sc = FALSE,
sc_method = "knnor",
sc_min_k = 1,
sc_max_k = 10,
use_pl = FALSE,
pl_max_steps = 3,
pl_max = 1.00,
pl_anchor = 1.00,
pl_min = 0.00,
sustain_track = TRUE,
sustain_iso_code = "DEU",
sustain_region = NULL,
sustain_interval = 15,
epochs = 150,
batch_size = 32,
trace = TRUE,
ml_trace = 0,
log_dir = NULL,
log_write_interval = 10,
n_cores = auto_n_cores(),
lr_rate=1e-3,
lr_warm_up_ratio=0.02,
optimizer="adamw"
)
classifier_with_fe$reliability$test_metric_mean
bert_modeling$get_model_info()
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
running_num_figures=1
running_num_figures=running_num_figures+1
running_num_figures=running_num_figures+1
running_num_figures=running_num_figures+1
library(aifeducation)
prepare_session()
example_data <- imdb_movie_reviews
example_data$label <- as.character(example_data$label)
example_data$label[c(76:100)] <- NA
example_data$label[c(201:250)] <- NA
table(example_data$label)
colnames(example_data)
example_data$bib_entry <- NA
example_data$license <- NA
colnames(example_data)
data_set_reviews_text <- LargeDataSetForText$new()
data_set_reviews_text$add_from_data.frame(example_data)
review_labels <- as.factor(example_data$label)
names(review_labels) <- example_data$id
base_model <- aife_transformer.make("bert")
base_model$create(
model_dir = "examples/my_own_transformer",
text_dataset = data_set_reviews_text,
vocab_size = 30522,
vocab_do_lower_case = FALSE,
max_position_embeddings = 512,
hidden_size = 768,
num_hidden_layer = 12,
num_attention_heads = 12,
intermediate_size = 3072,
hidden_act = "gelu",
hidden_dropout_prob = 0.1,
sustain_track = TRUE,
sustain_iso_code = "DEU",
sustain_region = NULL,
sustain_interval = 15,
trace = TRUE,
log_dir = NULL,
log_write_interval = 2
)
base_model <- aife_transformer.make("bert")
base_model$train(
output_dir = "examples/my_own_transformer_trained",
model_dir_path = "examples/my_own_transformer",
text_dataset = data_set_reviews_text,
p_mask = 0.15,
whole_word = TRUE,
val_size = 0.1,
n_epoch = 1,
batch_size = 12,
chunk_size = 250,
sustain_track = TRUE,
sustain_iso_code = "DEU",
sustain_region = NULL,
sustain_interval = 15,
trace = TRUE,
log_dir = NULL,
log_write_interval = 2
)
bert_modeling <- TextEmbeddingModel$new()
bert_modeling$configure(
model_label = "Text Embedding via BERT",
model_language = "english",
max_length = 512,
chunks = 4,
overlap = 30,
emb_layer_min = "middle",
emb_layer_max = "2_3_layer",
emb_pool_type = "average",
model_dir = "examples/bert_uncased"
)
bert_modeling$count_parameter()
bert_modeling$get_n_features()
devtools::load_all()
devtools::document()
576/768
path_test_data=testthat::test_path("test_data/LargeDataSetForTexts/single_text/Text_A")
list.files(path_test_data)
files=list.files(path_test_data)
files
files=list.files(path_test_data,full.names = TRUE)
files
test_that("get_file_extension", {
path_test_data=testthat::test_path("test_data/LargeDataSetForTexts/single_text/Text_A")
files=list.files(path_test_data,full.names = TRUE)
for(file in files){
expect_equal(get_file_extension(file),"txt")
}
})
dir_path=testthat::test_path("test_data/LargeDataSetForTexts/single_text")
dir_path=testthat::test_path("test_data/LargeDataSetForTexts/single_text")
files=list.files(path_test_data,full.names = TRUE,
pattern=".txt")
for(file in files){
expect_equal(get_file_extension(file),"txt")
}
test_that("get_file_extension", {
dir_path=testthat::test_path("test_data/LargeDataSetForTexts/single_text")
files=list.files(path_test_data,full.names = TRUE,
pattern=".txt")
for(file in files){
expect_equal(get_file_extension(file),"txt")
}
dir_path=testthat::test_path("test_data/LargeDataSetForTexts/single_text")
files=list.files(path_test_data,full.names = TRUE,
pattern=".pdf")
for(file in files){
expect_equal(get_file_extension(file),"pdf")
}
dir_path=testthat::test_path("test_data/LargeDataSetForTexts/single_text")
files=list.files(path_test_data,full.names = TRUE,
pattern=".xlsx")
for(file in files){
expect_equal(get_file_extension(file),"xlsx")
}
})
test_that("tmp_dir", {
expect_no_error(create_and_get_tmp_dir())
expect_no_error(clean_tmp_dir())
})
class_vector_to_py_dataset(c("a","b","b","c"))
class_vector_to_py_dataset(c(0,0,1,1,2,0))
class_vector_to_py_dataset(c(0,0,1,1,2,0))
vec=c(0,0,1,1,2,0)
names(vec)=c("A","B","C","d","e")
class_vector_to_py_dataset(vec)
vec=c(0,0,1,1,2,0)
names(vec)=c("A","B","C","d","e")
dataset=class_vector_to_py_dataset(vec)
class(dataset)
expect_s4_class(dataset,class="datasets.arrow_dataset.Dataset")
vec=c(0,0,1,1,2,0)
names(vec)=c("A","B","C","d","e")
dataset=class_vector_to_py_dataset(vec)
expect_s4_class(dataset,class="datasets.arrow_dataset.Dataset")
expect_s4_class(x=dataset,class="datasets.arrow_dataset.Dataset")
expect_s3_class(x=dataset,class="datasets.arrow_dataset.Dataset")
expect_s3_class(object=dataset,class="datasets.arrow_dataset.Dataset")
dataset[["id"]]
vec=c(0,0,1,1,2,0)
names(vec)=c("A","B","C","d","e","f")
dataset=class_vector_to_py_dataset(vec)
expect_s3_class(object=dataset,class="datasets.arrow_dataset.Dataset")
dataset
test_that("class_vector_to_py_dataset", {
vec=c(0,0,1,1,2,0)
name_vector=c("A","B","C","d","e","f")
names(vec)=name_vector
dataset=class_vector_to_py_dataset(vec)
expect_s3_class(object=dataset,class="datasets.arrow_dataset.Dataset")
expect_equal(dataset[["id"]],name_vector)
expect_equal(dataset[["labels"]],vec)
})
dataset[["id"]]
name_vector
name_vector=c("A","B","C","d","e","f")
names(vec)=name_vector
name_vector
expect_equal(dataset[["id"]],name_vector)
test_that("class_vector_to_py_dataset", {
vec=c(0,0,1,1,2,0)
name_vector=c("A","B","C","d","e","f")
names(vec)=name_vector
dataset=class_vector_to_py_dataset(vec)
expect_s3_class(object=dataset,class="datasets.arrow_dataset.Dataset")
expect_equal(dataset[["id"]],name_vector)
expect_equal(dataset[["labels"]],vec)
})
dataset[["labels"]]
vec
expect_equal(dataset[["labels"]],unnames(vec))
expect_equal(dataset[["labels"]],unname(vec))
test_that("class_vector_to_py_dataset", {
vec=c(0,0,1,1,2,0)
name_vector=c("A","B","C","d","e","f")
names(vec)=name_vector
dataset=class_vector_to_py_dataset(vec)
expect_s3_class(object=dataset,class="datasets.arrow_dataset.Dataset")
expect_equal(dataset[["id"]],name_vector)
expect_equal(dataset[["labels"]],unname(vec))
})
test_that("get_alpha_3_codes", {
expect_vector(get_alpha_3_codes())
})
devtools::document()
devtools::load_all()
start_aifeducation_studio()
devtools::load_all()
start_aifeducation_studio()
install.packages("~/aifeducation_1.1.0.9000.tar.gz", repos = NULL, type = "source")
devtools::load_all()
start_aifeducation_studio()
start_aifeducation_studio()
start_aifeducation_studio()
test_data=imdb_movie_reviews
for(i in i:nrow(test_data)){
for(i in i:nrow(test_data)){
writeLines(text=test_data$text[i],
con=pate0("C:/Users/User/Desktop/aifeducation_test_files/imdb_movie_reviews_raw",test_data$id[i],".txt"))
}
i:nrow(test_data)
for(i in 1:nrow(test_data)){
writeLines(text=test_data$text[i],
con=pate0("C:/Users/User/Desktop/aifeducation_test_files/imdb_movie_reviews_raw",test_data$id[i],".txt"))
}
for(i in 1:nrow(test_data)){
writeLines(text=test_data$text[i],
con=paste0("C:/Users/User/Desktop/aifeducation_test_files/imdb_movie_reviews_raw",test_data$id[i],".txt"))
}
for(i in 1:nrow(test_data)){
writeLines(text=test_data$text[i],
con=paste0("C:/Users/User/Desktop/aifeducation_test_files/imdb_movie_reviews_raw/id_",test_data$id[i],".txt"))
}
start_aifeducation_studio()
devtools::load_all()
start_aifeducation_studio()
load("~/aifeducation/inst/studio_app/arguments.rda")
args
# Set up py env
prepare_session(
env_type=args[[1]]$meta_args$py_environment_type,
envname=args[[1]]$meta_args$py_env_name
)
#Create object
object=create_object(args[[1]]$meta_args$object_class)
requested_methods=names(args)
names(args)
method="train"
# add missing objects to arguments by loading them
args[[method]]$args=add_missing_args(
args=args[[method]]$args,
path_args=args[[method]]$path_args,
meta_args=args[[method]]$meta_args
)
args[[method]]$args
#Call Method
do.call(what = object[[method]],args=args[[method]]$args)
start_aifeducation_studio()
load("~/aifeducation/inst/studio_app/arguments.rda")
# Set up py env
prepare_session(
env_type=args[[1]]$meta_args$py_environment_type,
envname=args[[1]]$meta_args$py_env_name
)
#Create object
object=create_object(args[[1]]$meta_args$object_class)
requested_methods=names(args)
for(method in requested_methods){
# add missing objects to arguments by loading them
args[[method]]$args=add_missing_args(
args=args[[method]]$args,
path_args=args[[method]]$path_args,
meta_args=args[[method]]$meta_args
)
#Call Method
do.call(what = object[[method]],args=args[[method]]$args)
}
reticulate::py_last_error()
start_aifeducation_studio()
start_aifeducation_studio()
