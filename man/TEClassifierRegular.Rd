% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/TEClassifierRegular.R
\name{TEClassifierRegular}
\alias{TEClassifierRegular}
\title{Text embedding classifier with a neural net}
\value{
Objects of this class are used for assigning texts to classes/categories. For
the creation and training of a classifier an object of class \link{EmbeddedText} and a \code{factor}
are necessary. The object of class \link{EmbeddedText} contains the numerical text
representations (text embeddings) of the raw texts generated by an object of class
\link{TextEmbeddingModel}. The \code{factor} contains the classes/categories for every
text. Missing values (unlabeled cases) are supported. For predictions an object of class
\link{EmbeddedText} has to be used which was created with the same text embedding model as
for training.
}
\description{
Abstract class for neural nets with 'keras'/'tensorflow' and
'pytorch'.
}
\seealso{
Other Classification: 
\code{\link{DataManagerClassifier}},
\code{\link{TEClassifierProtoNet}},
\code{\link{TextEmbeddingClassifierNeuralNet}}
}
\concept{Classification}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{model}}{('tensorflow_model' or 'pytorch_model')\cr
Field for storing the tensorflow or pytorch model after loading.}

\item{\code{model_config}}{('list()')\cr
List for storing information about the configuration of the model.}

\item{\code{last_training}}{('list()')\cr
List for storing the history, the configuration, and the results of the last training. This
information will be overwritten if a new training is started.
\itemize{
\item{\code{last_training$start_time: }Time point when training started.}
\item{\code{last_training$learning_time: }Duration of the training process.}
\item{\code{last_training$finish_time: }Time when the last training finished.}
\item{\code{last_training$history: }History of the last training.}
\item{\code{last_training$data: }Object of class \code{table} storing the initial frequencies of the passed data.}
\item{\code{last_training$config: }List storing the configuration used for the last training.}
}}

\item{\code{reliability}}{('list()')\cr
List for storing central reliability measures of the last training.
\itemize{
\item{\code{reliability$test_metric: }Array containing the reliability measures for the validation data for
every fold and step (in case of pseudo-labeling).}
\item{\code{reliability$test_metric_mean: }Array containing the reliability measures for the validation data for..
The values represent the mean values for every fold.}
\item{\code{reliability$raw_iota_objects: }List containing all iota_object generated with the package \code{iotarelr}
for every fold at the end of the last training.}
\itemize{
\item{\code{reliability$raw_iota_objects$iota_objects_end: }List of objects with class \code{iotarelr_iota2} containing the
estimated iota reliability of the second generation for the final model
for every fold.}
\item{\code{reliability$raw_iota_objects$iota_objects_end_free: }List of objects with class \code{iotarelr_iota2} containing the
estimated iota reliability of the second generation for the final model
for every fold. Please note that the model is estimated without
forcing the Assignment Error Matrix to be in line with the assumption of weak superiority.}
}
}
\item{\code{reliability$iota_object_end: }Object of class \code{iotarelr_iota2} as a mean of the individual objects
for every fold.
\item{\code{reliability$iota_object_end_free: }Object of class \code{iotarelr_iota2} as a mean of the individual objects
for every fold. Please note that the model is estimated without
forcing the Assignment Error Matrix to be in line with the assumption of weak superiority.}
\item{\code{reliability$standard_measures_end: }Object of class \code{list} containing the final
measures for precision, recall, and f1 for every fold.}
\item{\code{reliability$standard_measures_mean: }\code{matrix} containing the mean
measures for precision, recall, and f1.}
}}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-TEClassifierRegular-new}{\code{TEClassifierRegular$new()}}
\item \href{#method-TEClassifierRegular-train}{\code{TEClassifierRegular$train()}}
\item \href{#method-TEClassifierRegular-predict}{\code{TEClassifierRegular$predict()}}
\item \href{#method-TEClassifierRegular-check_embedding_model}{\code{TEClassifierRegular$check_embedding_model()}}
\item \href{#method-TEClassifierRegular-get_model_info}{\code{TEClassifierRegular$get_model_info()}}
\item \href{#method-TEClassifierRegular-get_text_embedding_model}{\code{TEClassifierRegular$get_text_embedding_model()}}
\item \href{#method-TEClassifierRegular-set_publication_info}{\code{TEClassifierRegular$set_publication_info()}}
\item \href{#method-TEClassifierRegular-get_publication_info}{\code{TEClassifierRegular$get_publication_info()}}
\item \href{#method-TEClassifierRegular-set_software_license}{\code{TEClassifierRegular$set_software_license()}}
\item \href{#method-TEClassifierRegular-get_software_license}{\code{TEClassifierRegular$get_software_license()}}
\item \href{#method-TEClassifierRegular-set_documentation_license}{\code{TEClassifierRegular$set_documentation_license()}}
\item \href{#method-TEClassifierRegular-get_documentation_license}{\code{TEClassifierRegular$get_documentation_license()}}
\item \href{#method-TEClassifierRegular-set_model_description}{\code{TEClassifierRegular$set_model_description()}}
\item \href{#method-TEClassifierRegular-get_model_description}{\code{TEClassifierRegular$get_model_description()}}
\item \href{#method-TEClassifierRegular-save_model}{\code{TEClassifierRegular$save_model()}}
\item \href{#method-TEClassifierRegular-load_model}{\code{TEClassifierRegular$load_model()}}
\item \href{#method-TEClassifierRegular-get_package_versions}{\code{TEClassifierRegular$get_package_versions()}}
\item \href{#method-TEClassifierRegular-get_sustainability_data}{\code{TEClassifierRegular$get_sustainability_data()}}
\item \href{#method-TEClassifierRegular-get_ml_framework}{\code{TEClassifierRegular$get_ml_framework()}}
\item \href{#method-TEClassifierRegular-clone}{\code{TEClassifierRegular$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TEClassifierRegular-new"></a>}}
\if{latex}{\out{\hypertarget{method-TEClassifierRegular-new}{}}}
\subsection{Method \code{new()}}{
Creating a new instance of this class.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TEClassifierRegular$new(
  ml_framework = aifeducation_config$get_framework(),
  name = NULL,
  label = NULL,
  text_embeddings = NULL,
  targets = NULL,
  hidden = c(128),
  rec = c(128),
  self_attention_heads = 0,
  intermediate_size = NULL,
  attention_type = "fourier",
  add_pos_embedding = TRUE,
  rec_dropout = 0.1,
  repeat_encoder = 1,
  dense_dropout = 0.4,
  recurrent_dropout = 0.4,
  encoder_dropout = 0.1,
  optimizer = "adam"
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{ml_framework}}{\code{string} Framework to use for training and inference.
\code{ml_framework="tensorflow"} for 'tensorflow' and \code{ml_framework="pytorch"}
for 'pytorch'}

\item{\code{name}}{\code{Character} Name of the new classifier. Please refer to
common name conventions. Free text can be used with parameter \code{label}.}

\item{\code{label}}{\code{Character} Label for the new classifier. Here you can use
free text.}

\item{\code{text_embeddings}}{An object of class\code{TextEmbeddingModel}.}

\item{\code{targets}}{\code{factor} containing the target values of the classifier.}

\item{\code{hidden}}{\code{vector} containing the number of neurons for each dense layer.
The length of the vector determines the number of dense layers. If you want no dense layer,
set this parameter to \code{NULL}.}

\item{\code{rec}}{\code{vector} containing the number of neurons for each recurrent layer.
The length of the vector determines the number of dense layers. If you want no dense layer,
set this parameter to \code{NULL}.}

\item{\code{self_attention_heads}}{\code{integer} determining the number of attention heads
for a self-attention layer. Only relevant if \code{attention_type="multihead"}}

\item{\code{intermediate_size}}{\code{int} determining the size of the projection layer within
a each transformer encoder.}

\item{\code{attention_type}}{\code{string} Choose the relevant attention type. Possible values
are \code{"fourier"} and \code{multihead}.}

\item{\code{add_pos_embedding}}{\code{bool} \code{TRUE} if positional embedding should be used.}

\item{\code{rec_dropout}}{\code{double} ranging between 0 and lower 1, determining the
dropout between bidirectional gru layers.}

\item{\code{repeat_encoder}}{\code{int} determining how many times the encoder should be
added to the network.}

\item{\code{dense_dropout}}{\code{double} ranging between 0 and lower 1, determining the
dropout between dense layers.}

\item{\code{recurrent_dropout}}{\code{double} ranging between 0 and lower 1, determining the
recurrent dropout for each recurrent layer. Only relevant for keras models.}

\item{\code{encoder_dropout}}{\code{double} ranging between 0 and lower 1, determining the
dropout for the dense projection within the encoder layers.}

\item{\code{optimizer}}{Object of class \code{keras.optimizers}.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Returns an object of class \link{TextEmbeddingClassifierNeuralNet} which is ready for
training.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TEClassifierRegular-train"></a>}}
\if{latex}{\out{\hypertarget{method-TEClassifierRegular-train}{}}}
\subsection{Method \code{train()}}{
Method for training a neural net.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TEClassifierRegular$train(
  data_embeddings,
  data_targets,
  data_folds = 5,
  data_val_size = 0.25,
  balance_class_weights = TRUE,
  balance_sequence_length = TRUE,
  use_sc = TRUE,
  sc_method = "dbsmote",
  sc_min_k = 1,
  sc_max_k = 10,
  use_pl = TRUE,
  pl_max_steps = 3,
  pl_max = 1,
  pl_anchor = 1,
  pl_min = 0,
  sustain_track = TRUE,
  sustain_iso_code = NULL,
  sustain_region = NULL,
  sustain_interval = 15,
  epochs = 40,
  batch_size = 32,
  dir_checkpoint,
  trace = TRUE,
  keras_trace = 2,
  pytorch_trace = 1
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{data_embeddings}}{Object of class \code{TextEmbeddingModel}.}

\item{\code{data_targets}}{\code{Factor} containing the labels for cases
stored in \code{data_embeddings}. Factor must be named and has to use the
same names used in \code{data_embeddings}.}

\item{\code{data_folds}}{\code{int} determining the number of cross-fold
samples.}

\item{\code{data_val_size}}{\code{double} between 0 and 1, indicating the proportion of cases of each class
which should be used for the validation sample during the estimation of the baseline model.
The remaining cases are part of the training data.}

\item{\code{balance_class_weights}}{\code{bool} If \code{TRUE} class weights are
generated based on the frequencies of the training data with the method
Inverse Class Frequency'. If \code{FALSE} each class has the weight 1.}

\item{\code{balance_sequence_length}}{\code{bool} If \code{TRUE} sample weights are
generated for the length of sequences based on the frequencies of the training data with the method
Inverse Class Frequency'. If \code{FALSE} each sequences length has the weight 1.}

\item{\code{use_sc}}{\code{bool} \code{TRUE} if the estimation should integrate
balanced synthetic cases. \code{FALSE} if not.}

\item{\code{sc_method}}{\code{vector} containing the methods for generating
synthetic cases via 'smotefamily'. Multiple methods can
be passed. Currently \code{sc_method=c("adas")}, \code{sc_method=c("smote")}
and \code{sc_method=c("dbsmote")} are possible.}

\item{\code{sc_min_k}}{\code{int} determining the minimal number of k which is used
for creating synthetic units.}

\item{\code{sc_max_k}}{\code{int} determining the maximal number of k which is used
for creating synthetic units.}

\item{\code{use_pl}}{\code{bool} \code{TRUE} if the estimation should integrate
balanced pseudo-labeling. \code{FALSE} if not.}

\item{\code{pl_max_steps}}{\code{int} determining the maximum number of steps during
pseudo-labeling.}

\item{\code{pl_max}}{\code{double} between 0 and 1, setting the maximal level of
confidence for considering a case for pseudo-labeling.}

\item{\code{pl_anchor}}{\code{double} between 0 and 1 indicating the reference
point for sorting the new cases of every label. See notes for more details.}

\item{\code{pl_min}}{\code{double} between 0 and 1, setting the minimal level of
confidence for considering a case for pseudo-labeling.}

\item{\code{sustain_track}}{\code{bool} If \code{TRUE} energy consumption is tracked
during training via the python library codecarbon.}

\item{\code{sustain_iso_code}}{\code{string} ISO code (Alpha-3-Code) for the country. This variable
must be set if sustainability should be tracked. A list can be found on
Wikipedia: \url{https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes}.}

\item{\code{sustain_region}}{Region within a country. Only available for USA and
Canada See the documentation of codecarbon for more information.
\url{https://mlco2.github.io/codecarbon/parameters.html}}

\item{\code{sustain_interval}}{\code{integer} Interval in seconds for measuring power
usage.}

\item{\code{epochs}}{\code{int} Number of training epochs.}

\item{\code{batch_size}}{\code{int} Size of batches.}

\item{\code{dir_checkpoint}}{\code{string} Path to the directory where
the checkpoint during training should be saved. If the directory does not
exist, it is created.}

\item{\code{trace}}{\code{bool} \code{TRUE}, if information about the estimation
phase should be printed to the console.}

\item{\code{keras_trace}}{\code{int} \code{keras_trace=0} does not print any
information about the training process from keras on the console.}

\item{\code{pytorch_trace}}{\code{int} \code{pytorch_trace=0} does not print any
information about the training process from pytorch on the console.
\code{pytorch_trace=1} prints a progress bar.}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
\itemize{

\item{\code{sc_max_k: }All values from sc_min_k up to sc_max_k are successively used. If
the number of sc_max_k is too high, the value is reduced to a number that
allows the calculating of synthetic units.}

\item{\code{pl_anchor: }With the help of this value, the new cases are sorted. For
this aim, the distance from the anchor is calculated and all cases are arranged
into an ascending order.
}
}
}

\subsection{Returns}{
Function does not return a value. It changes the object into a trained
classifier.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TEClassifierRegular-predict"></a>}}
\if{latex}{\out{\hypertarget{method-TEClassifierRegular-predict}{}}}
\subsection{Method \code{predict()}}{
Method for predicting new data with a trained neural net.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TEClassifierRegular$predict(newdata, batch_size = 32, verbose = 1)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{newdata}}{Object of class \code{TextEmbeddingModel} or
\code{data.frame} for which predictions should be made.}

\item{\code{batch_size}}{\code{int} Size of batches.}

\item{\code{verbose}}{\code{int} \code{verbose=0} does not cat any
information about the training process from keras on the console.
\code{verbose=1} prints a progress bar. \code{verbose=2} prints
one line of information for every epoch.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Returns a \code{data.frame} containing the predictions and
the probabilities of the different labels for each case.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TEClassifierRegular-check_embedding_model"></a>}}
\if{latex}{\out{\hypertarget{method-TEClassifierRegular-check_embedding_model}{}}}
\subsection{Method \code{check_embedding_model()}}{
Method for checking if the provided text embeddings are
created with the same \link{TextEmbeddingModel} as the classifier.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TEClassifierRegular$check_embedding_model(text_embeddings)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{text_embeddings}}{Object of class \link{EmbeddedText}.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
\code{TRUE} if the underlying \link{TextEmbeddingModel} are the same.
\code{FALSE} if the models differ.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TEClassifierRegular-get_model_info"></a>}}
\if{latex}{\out{\hypertarget{method-TEClassifierRegular-get_model_info}{}}}
\subsection{Method \code{get_model_info()}}{
Method for requesting the model information
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TEClassifierRegular$get_model_info()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
\code{list} of all relevant model information
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TEClassifierRegular-get_text_embedding_model"></a>}}
\if{latex}{\out{\hypertarget{method-TEClassifierRegular-get_text_embedding_model}{}}}
\subsection{Method \code{get_text_embedding_model()}}{
Method for requesting the text embedding model information
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TEClassifierRegular$get_text_embedding_model()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
\code{list} of all relevant model information on the text embedding model
underlying the classifier
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TEClassifierRegular-set_publication_info"></a>}}
\if{latex}{\out{\hypertarget{method-TEClassifierRegular-set_publication_info}{}}}
\subsection{Method \code{set_publication_info()}}{
Method for setting publication information of the classifier
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TEClassifierRegular$set_publication_info(authors, citation, url = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{authors}}{List of authors.}

\item{\code{citation}}{Free text citation.}

\item{\code{url}}{URL of a corresponding homepage.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Function does not return a value. It is used for setting the private
members for publication information.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TEClassifierRegular-get_publication_info"></a>}}
\if{latex}{\out{\hypertarget{method-TEClassifierRegular-get_publication_info}{}}}
\subsection{Method \code{get_publication_info()}}{
Method for requesting the bibliographic information of the classifier.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TEClassifierRegular$get_publication_info()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
\code{list} with all saved bibliographic information.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TEClassifierRegular-set_software_license"></a>}}
\if{latex}{\out{\hypertarget{method-TEClassifierRegular-set_software_license}{}}}
\subsection{Method \code{set_software_license()}}{
Method for setting the license of the classifier.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TEClassifierRegular$set_software_license(license = "GPL-3")}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{license}}{\code{string} containing the abbreviation of the license or
the license text.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Function does not return a value. It is used for setting the private member for
the software license of the model.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TEClassifierRegular-get_software_license"></a>}}
\if{latex}{\out{\hypertarget{method-TEClassifierRegular-get_software_license}{}}}
\subsection{Method \code{get_software_license()}}{
Method for getting the license of the classifier.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TEClassifierRegular$get_software_license()}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{license}}{\code{string} containing the abbreviation of the license or
the license text.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
\code{string} representing the license for the software.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TEClassifierRegular-set_documentation_license"></a>}}
\if{latex}{\out{\hypertarget{method-TEClassifierRegular-set_documentation_license}{}}}
\subsection{Method \code{set_documentation_license()}}{
Method for setting the license of the classifier's documentation.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TEClassifierRegular$set_documentation_license(license = "CC BY-SA")}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{license}}{\code{string} containing the abbreviation of the license or
the license text.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Function does not return a value. It is used for setting the private member for
the documentation license of the model.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TEClassifierRegular-get_documentation_license"></a>}}
\if{latex}{\out{\hypertarget{method-TEClassifierRegular-get_documentation_license}{}}}
\subsection{Method \code{get_documentation_license()}}{
Method for getting the license of the classifier's documentation.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TEClassifierRegular$get_documentation_license()}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{license}}{\code{string} containing the abbreviation of the license or
the license text.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Returns the license as a \code{string}.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TEClassifierRegular-set_model_description"></a>}}
\if{latex}{\out{\hypertarget{method-TEClassifierRegular-set_model_description}{}}}
\subsection{Method \code{set_model_description()}}{
Method for setting a description of the classifier.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TEClassifierRegular$set_model_description(
  eng = NULL,
  native = NULL,
  abstract_eng = NULL,
  abstract_native = NULL,
  keywords_eng = NULL,
  keywords_native = NULL
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{eng}}{\code{string} A text describing the training of the learner,
its theoretical and empirical background, and the different output labels
in English.}

\item{\code{native}}{\code{string} A text describing the training of the learner,
its theoretical and empirical background, and the different output labels
in the native language of the classifier.}

\item{\code{abstract_eng}}{\code{string} A text providing a summary of the description
in English.}

\item{\code{abstract_native}}{\code{string} A text providing a summary of the description
in the native language of the classifier.}

\item{\code{keywords_eng}}{\code{vector} of keyword in English.}

\item{\code{keywords_native}}{\code{vector} of keyword in the native language of the classifier.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Function does not return a value. It is used for setting the private members for the
description of the model.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TEClassifierRegular-get_model_description"></a>}}
\if{latex}{\out{\hypertarget{method-TEClassifierRegular-get_model_description}{}}}
\subsection{Method \code{get_model_description()}}{
Method for requesting the model description.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TEClassifierRegular$get_model_description()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
\code{list} with the description of the classifier in English
and the native language.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TEClassifierRegular-save_model"></a>}}
\if{latex}{\out{\hypertarget{method-TEClassifierRegular-save_model}{}}}
\subsection{Method \code{save_model()}}{
Method for saving a model to 'Keras v3 format',
'tensorflow' SavedModel format or h5 format.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TEClassifierRegular$save_model(dir_path, save_format = "default")}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{dir_path}}{\code{string()} Path of the directory where the model should be
saved.}

\item{\code{save_format}}{Format for saving the model. For 'tensorflow'/'keras' models
\code{"keras"} for 'Keras v3 format',
\code{"tf"} for SavedModel
or \code{"h5"} for HDF5.
For 'pytorch' models \code{"safetensors"} for 'safetensors' or
\code{"pt"} for 'pytorch' via pickle.
Use \code{"default"} for the standard format. This is keras for
'tensorflow'/'keras' models and safetensors for 'pytorch' models.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Function does not return a value. It saves the model to disk.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TEClassifierRegular-load_model"></a>}}
\if{latex}{\out{\hypertarget{method-TEClassifierRegular-load_model}{}}}
\subsection{Method \code{load_model()}}{
Method for importing a model from 'Keras v3 format',
'tensorflow' SavedModel format or h5 format.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TEClassifierRegular$load_model(dir_path, ml_framework = "auto")}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{dir_path}}{\code{string()} Path of the directory where the model is
saved.}

\item{\code{ml_framework}}{\code{string} Determines the machine learning framework
for using the model. Possible are \code{ml_framework="pytorch"} for 'pytorch',
\code{ml_framework="tensorflow"} for 'tensorflow', and \code{ml_framework="auto"}.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Function does not return a value. It is used to load the weights
of a model.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TEClassifierRegular-get_package_versions"></a>}}
\if{latex}{\out{\hypertarget{method-TEClassifierRegular-get_package_versions}{}}}
\subsection{Method \code{get_package_versions()}}{
Method for requesting a summary of the R and python packages'
versions used for creating the classifier.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TEClassifierRegular$get_package_versions()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
Returns a \code{list} containing the versions of the relevant
R and python packages.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TEClassifierRegular-get_sustainability_data"></a>}}
\if{latex}{\out{\hypertarget{method-TEClassifierRegular-get_sustainability_data}{}}}
\subsection{Method \code{get_sustainability_data()}}{
Method for requesting a summary of tracked energy consumption
during training and an estimate of the resulting CO2 equivalents in kg.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TEClassifierRegular$get_sustainability_data()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
Returns a \code{list} containing the tracked energy consumption,
CO2 equivalents in kg, information on the tracker used, and technical
information on the training infrastructure.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TEClassifierRegular-get_ml_framework"></a>}}
\if{latex}{\out{\hypertarget{method-TEClassifierRegular-get_ml_framework}{}}}
\subsection{Method \code{get_ml_framework()}}{
Method for requesting the machine learning framework used
for the classifier.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TEClassifierRegular$get_ml_framework()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
Returns a \code{string} describing the machine learning framework used
for the classifier
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TEClassifierRegular-clone"></a>}}
\if{latex}{\out{\hypertarget{method-TEClassifierRegular-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TEClassifierRegular$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
