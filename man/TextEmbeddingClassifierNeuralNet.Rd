% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/te_classifier_neuralnet_model.R
\name{TextEmbeddingClassifierNeuralNet}
\alias{TextEmbeddingClassifierNeuralNet}
\title{Text Embedding Classifier with a Neural Net}
\description{
Abstract class for neural nets with keras and
tensorflow
}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{name}}{('character()')\cr
Name of the classifier.}

\item{\code{label}}{('character()')\cr
Label of the classifier used as the individual title.}

\item{\code{date}}{('date()')\cr
Date of the first creation of the classifier.}

\item{\code{text_embedding_model}}{('list()')\cr
List for storing information about the underlying text embedding model.
This information ensures that a classifier is only used with data from
the correct text embedding model and ensures the correct handling of the
embeddings.}

\item{\code{bundeled_model}}{('bundle object')\cr
Object for storing the keras model of the neural net. Saved as bundled
object with help of the package \link[bundle]{bundle} for serialization.}

\item{\code{model_config}}{('list()')\cr
List for storing information about the configuration of the model. This
information is used for predicting new data.
\itemize{
\item{\code{model_config$n_gru: }}{Number of gru layers.}
\item{\code{model_config$n_hidden: }}{Number of dense layers.}
\item{\code{model_config$target_levels: }}{Levels of the target variable. Do not change this manually.}
\item{\code{model_config$input_variables: }}{Order and name of the input variables. Do not change this manually.}
\item{\code{model_config$init_config: }}{List storing all parameters passed to method new().}
}}

\item{\code{last_training}}{('list()')\cr
List for storing the history and the results of the last training. This
information will be overwritten if a new training is started.
\itemize{
\item{\code{last_training$learning_time: }}{Duration of the training process.}
\item{\code{config$history: }}{History of the last training.}
\item{\code{config$data: }}{Object of class table storing the initial frequencies of the passed data.}
\item{\code{config$data_pb:l }}{Matrix storing the number of additional cases (test and training) added
during balanced pseudo labeling. The rows refer to folds and final training.
The columns refer to the steps during pseudo labeling.}
\item{\code{config$data_bsc_test: }}{Matrix storing the number of cases for each category used for testing
during the phase of balanced synthetic units. Please note that the
frequencies include original and synthetic cases. In terms that the number
of original and synthetic cases exceeds the limit for the majority classes
the frequency represents the number of cases created by cluster analysis.}
\item{\code{config$date: }}{Time when the last training finished.}
\item{\code{config$config: }}{List storing which kind of estimation was requested during last training.
\itemize{
\item{\code{config$config$use_bsc:  }}{\code{TRUE} if  balanced synthetic cases was requested. \code{FALSE}
if not.}
\item{\code{config$config$use_baseline: }}{\code{TRUE} if baseline estimation was requested. \code{FALSE}
if not.}
\item{\code{ config$config$use_bpl: }}{\code{TRUE} if  balanced pseudo labeling cases was requested. \code{FALSE}
if not.}
}}
}}

\item{\code{reliability}}{('list()')\cr
List for storing central reliability measures of the last training.
\itemize{
\item{\code{reliability$val_metric: }}{Array containing the reliability measures for the validation data for
every fold, method, and step (in case of pseudo labeling).}
\item{\code{reliability$val_metric_mean: }}{Array containing the reliability measures for the validation data for
every method and step (in case of pseudo labeling). The values represent
the mean values for every fold.}
\item{\code{reliability$raw_iota_objects: }}{List containing all iota_object generated with the package \link[iotarelr]{iotarelr}
for every fold at the start and the end of the last training.
\itemize{
\item{\code{reliability$raw_iota_objects$iota_objects_start: }}{List of objects with class \code{iotarelr_iota2} containing the
estimated iota reliability of the second generation for the baseline model
for every fold.
If the estimation of the baseline model is not requested the list is
set to \code{NULL}.}
\item{\code{reliability$raw_iota_objects$iota_objects_end: }}{List of objects with class \code{iotarelr_iota2} containing the
estimated iota reliability of the second generation for the final model
for every fold. Depending of the requested training method these values
refer to the baseline model, a trained model on the basis of balanced
synthetic cases, balanced pseudo labeling or a combination of balanced
synthetic cases with pseudo labeling.}
\item{\code{reliability$raw_iota_objects$iota_objects_start_free: }}{List of objects with class \code{iotarelr_iota2} containing the
estimated iota reliability of the second generation for the baseline model
for every fold.
If the estimation of the baseline model is not requested the list is
set to \code{NULL}.Please note that the model is estimated without
forcing the Assignment Error Matrix to be in line with the assumption of weak superiority.}
\item{\code{reliability$raw_iota_objects$iota_objects_end_free: }}{List of objects with class \code{iotarelr_iota2} containing the
estimated iota reliability of the second generation for the final model
for every fold. Depending of the requested training method these values
refer to the baseline model, a trained model on the basis of balanced
synthetic cases, balanced pseudo labeling or a combination of balanced
synthetic cases with pseudo labeling.
Please note that the model is estimated without
forcing the Assignment Error Matrix to be in line with the assumption of weak superiority.}
}
}
\item{\code{reliability$iota_object_start: }}{Object of class \code{iotarelr_iota2} as a mean of the individual objects
for every fold. If the estimation of the baseline model is not requested the list is
set to \code{NULL}.}
\item{\code{ reliability$iota_object_start_free: }}{Object of class \code{iotarelr_iota2} as a mean of the individual objects
for every fold. If the estimation of the baseline model is not requested the list is
set to \code{NULL}.
Please note that the model is estimated without
forcing the Assignment Error Matrix to be in line with the assumption of weak superiority.}
\item{\code{reliability$iota_object_end: }}{Object of class \code{iotarelr_iota2} as a mean of the individual objects
for every fold.
Depending of the requested training method this object
refers to the baseline model, a trained model on the basis of balanced
synthetic cases, balanced pseudo labeling or a combination of balanced
synthetic cases with pseudo labeling.}
\item{\code{reliability$iota_object_end_free: }}{Object of class \code{iotarelr_iota2} as a mean of the individual objects
for every fold.
Depending of the requested training method this object
refers to the baseline model, a trained model on the basis of balanced
synthetic cases, balanced pseudo labeling or a combination of balanced
synthetic cases with pseudo labeling.
Please note that the model is estimated without
forcing the Assignment Error Matrix to be in line with the assumption of weak superiority.}
}}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-TextEmbeddingClassifierNeuralNet-new}{\code{TextEmbeddingClassifierNeuralNet$new()}}
\item \href{#method-TextEmbeddingClassifierNeuralNet-train}{\code{TextEmbeddingClassifierNeuralNet$train()}}
\item \href{#method-TextEmbeddingClassifierNeuralNet-predict}{\code{TextEmbeddingClassifierNeuralNet$predict()}}
\item \href{#method-TextEmbeddingClassifierNeuralNet-set_publication_info}{\code{TextEmbeddingClassifierNeuralNet$set_publication_info()}}
\item \href{#method-TextEmbeddingClassifierNeuralNet-get_publication_info}{\code{TextEmbeddingClassifierNeuralNet$get_publication_info()}}
\item \href{#method-TextEmbeddingClassifierNeuralNet-set_license}{\code{TextEmbeddingClassifierNeuralNet$set_license()}}
\item \href{#method-TextEmbeddingClassifierNeuralNet-get_license}{\code{TextEmbeddingClassifierNeuralNet$get_license()}}
\item \href{#method-TextEmbeddingClassifierNeuralNet-set_model_description}{\code{TextEmbeddingClassifierNeuralNet$set_model_description()}}
\item \href{#method-TextEmbeddingClassifierNeuralNet-get_model_description}{\code{TextEmbeddingClassifierNeuralNet$get_model_description()}}
\item \href{#method-TextEmbeddingClassifierNeuralNet-export_model}{\code{TextEmbeddingClassifierNeuralNet$export_model()}}
\item \href{#method-TextEmbeddingClassifierNeuralNet-import_model}{\code{TextEmbeddingClassifierNeuralNet$import_model()}}
\item \href{#method-TextEmbeddingClassifierNeuralNet-clone}{\code{TextEmbeddingClassifierNeuralNet$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TextEmbeddingClassifierNeuralNet-new"></a>}}
\if{latex}{\out{\hypertarget{method-TextEmbeddingClassifierNeuralNet-new}{}}}
\subsection{Method \code{new()}}{
Creating a new instance of this class.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TextEmbeddingClassifierNeuralNet$new(
  name = NULL,
  label = NULL,
  text_embeddings = NULL,
  targets = NULL,
  config = list(hidden = c(128), gru = c(128), dropout = 0.2, recurrent_dropout = 0,
    l2_regularizer = 0.001, optimizer = "adam", act_fct = "gelu", act_fct_last =
    "softmax", err_fct = "categorical_crossentropy")
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{name}}{\code{Character} Name of the new classifier. Please refer to
common name conventions. Free text can be used with parameter \code{label}.}

\item{\code{label}}{\code{Character} Label for the new classifier. Here you can use
free text.}

\item{\code{text_embeddings}}{An object of class\code{TextEmbeddingModel}.}

\item{\code{targets}}{\code{factor} containing the target values of the classifier.}

\item{\code{config}}{\code{list} containing the configuration of the neural net.}

\item{\code{config$hidden}}{\code{vector} containing the number of neurons for each dense layer.
The length of the vector determines the number of dense layers. If you want no dense layer
set this parameter to \code{NULL}.}

\item{\code{config$gru}}{\code{vector} containing the number of neurons for each gru layer.
The length of the vector determines the number of dense layers. If you want no dense layer
set this parameter to \code{NULL}.}

\item{\code{config$dropout}}{\code{double} ranging between 0 and lower 1 determining the
dropout for each gru layer.}

\item{\code{config$recurrent_dropout}}{\code{double} ranging between 0 and lower 1 determining the
recurrent dropout for each gru layer.}

\item{\code{l2_regularizer}}{\code{double} determining the l2 regularizer for every dense layer.}

\item{\code{optimizer}}{Object of class \code{keras.optimizers}.}

\item{\code{act_fct}}{\code{character} naming the activation function for all dense layers.}

\item{\code{act_fct_last}}{\code{character} naming the activation function for the last dense layers.}

\item{\code{err_fct}}{\code{character} naming the loss/error function for the neural net.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TextEmbeddingClassifierNeuralNet-train"></a>}}
\if{latex}{\out{\hypertarget{method-TextEmbeddingClassifierNeuralNet-train}{}}}
\subsection{Method \code{train()}}{
Method for training a neural net with keras and
tensorflow.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TextEmbeddingClassifierNeuralNet$train(
  data_embeddings,
  data_targets,
  data_n_valid_samples = 10,
  use_baseline = TRUE,
  bsl_val_size = 0.25,
  use_bsc = TRUE,
  bsc_methods = c("dbsmote"),
  bsc_max_k = 10,
  use_bpl = TRUE,
  bpl_max_steps = 10,
  bpl_inc_ratio = 0.25,
  bpl_anchor = 0.75,
  bpl_valid_size = 0.33,
  opt_model_reset = FALSE,
  epochs = 100,
  batch_size = 32,
  dir_checkpoint,
  trace = TRUE,
  view_metrics = FALSE,
  keras_trace = 2,
  n_cores = 2
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{data_embeddings}}{Object of class \code{TextEmbeddingModel}.}

\item{\code{data_targets}}{\code{Factor} containing the labels for cases
stored in \code{data_embeddings}. Factor must be named and has to use the
same names used in \code{data_embeddings}.}

\item{\code{data_n_valid_samples}}{\code{int} determining the number of cross-fold
samples.}

\item{\code{use_baseline}}{\code{bool} \code{TRUE} if the calculation of a baseline
model is requested. This option is only relevant for \code{use_bsc=TRUE} or
\code{use_pbl=TRUE}. If both are \code{FALSE} a baseline model is calculated.}

\item{\code{bsl_val_size}}{\code{double} between 0 and 1 indicating the proportion of cases of each label
which should be used for the validation sample during the estimation of the baseline model.
The remaining cases are part of the training data.}

\item{\code{use_bsc}}{\code{bool} \code{TRUE} if the estimation should integrate
balanced synthetic cases. \code{FALSE} if not.}

\item{\code{bsc_methods}}{\code{vector} containing the methods for generating
synthetic cases via \link[smotefamily]{smotefamily}. Multiple methods can
be passed. Currently \code{bsc_methods=c("adas")}, \code{bsc_methods=c("smote")}
and \code{bsc_methods=c("dbsmote")} are possible.}

\item{\code{bsc_max_k}}{\code{int} determining the maximal number of k which is used
for creating synthetic units.}

\item{\code{use_bpl}}{\code{bool} \code{TRUE} if the estimation should integrate
balanced pseudo labeling. \code{FALSE} if not.}

\item{\code{bpl_max_steps}}{\code{int} determining the maximal number of steps for
every application of balanced pseudo labeling.}

\item{\code{bpl_inc_ratio}}{\code{double} ratio between 0 and 1 indicating the
proportion of new cases which should used for further training. See notes
for more details.}

\item{\code{bpl_anchor}}{\code{double} between 0 and 1 indicating the reference
point for sorting the new cases of every label. See notes for more details.}

\item{\code{bpl_valid_size}}{\code{double} ratio between 0 and 1 determining the proportion
of new cases for every label which should be added to the validation sample during training.
The remaining cases are added to the training sample.}

\item{\code{opt_model_reset}}{\code{bool} \code{TRUE} if the model should be
reseted before training.}

\item{\code{epochs}}{\code{int} Number of training epochs.}

\item{\code{batch_size}}{\code{int} Size of batches.}

\item{\code{dir_checkpoint}}{\code{string} Path to the directory where
the checkpoint during training should be saved. If the directory does not
exists it is created.}

\item{\code{trace}}{\code{bool} \code{TRUE} if information about the estimation
phase should be printed to the console.}

\item{\code{view_metrics}}{\code{bool} \code{TRUE} if metrics should be printed
in the RStudie IDE.}

\item{\code{keras_trace}}{\code{int} \code{keras_trace=0} does not print any
information about the training process from keras on the console.
\code{keras_trace=1} print a progress bar. \code{keras_trace=2} prints
one line of information for every epoch.}

\item{\code{n_cores}}{\code{int} Number of cores used for creating synthetic units.}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
\itemize{

\item{bsc_max_k: }{All values from 2 up to bsc_max_k are successively used. If
the number of bsc_max_k is to high the value is reduced to a number that
allows the calculating of synthetic units.}

\item{bpl_inc_ratio: }{The ratio is applied to the label with the smallest number
of new cases. The resulting value is used for every label to ensure the balance
of all labels.}

\item{bpl_anchor: }{With the help of this value the new cases are sorted. For
this aim the distance from the anchor is calculated and all cases are arranged
into an increasing order.
}
}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TextEmbeddingClassifierNeuralNet-predict"></a>}}
\if{latex}{\out{\hypertarget{method-TextEmbeddingClassifierNeuralNet-predict}{}}}
\subsection{Method \code{predict()}}{
Method for prediciting new data with a trained neural net.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TextEmbeddingClassifierNeuralNet$predict(newdata)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{newdata}}{Object of class \code{TextEmbeddingModel} or
\code{data.frame} for which predictions should be made.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Returns a \code{data.frame} containing the predictions and
the probabilities of the different labels for each case.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TextEmbeddingClassifierNeuralNet-set_publication_info"></a>}}
\if{latex}{\out{\hypertarget{method-TextEmbeddingClassifierNeuralNet-set_publication_info}{}}}
\subsection{Method \code{set_publication_info()}}{
Method for setting publication information of the classifier
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TextEmbeddingClassifierNeuralNet$set_publication_info(
  type,
  autors,
  citation,
  url = NULL
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{type}}{\code{string} for choosing the type of information that should
be added. \code{type="developer"} for information about the developer of the
classifier and \code{type="trainer"} for information about persons who trained
the classifier. If you modify an already existing classifier please use
\code{type="modifier"}.}

\item{\code{autors}}{Person list of authors.}

\item{\code{citation}}{Free text citation.}

\item{\code{url}}{URL of a corresponding homepage.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TextEmbeddingClassifierNeuralNet-get_publication_info"></a>}}
\if{latex}{\out{\hypertarget{method-TextEmbeddingClassifierNeuralNet-get_publication_info}{}}}
\subsection{Method \code{get_publication_info()}}{
Method for requesting the publication information of the classifier.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TextEmbeddingClassifierNeuralNet$get_publication_info()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
\code{list} with all saved publication information.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TextEmbeddingClassifierNeuralNet-set_license"></a>}}
\if{latex}{\out{\hypertarget{method-TextEmbeddingClassifierNeuralNet-set_license}{}}}
\subsection{Method \code{set_license()}}{
Method for setting the license of the classifier.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TextEmbeddingClassifierNeuralNet$set_license(license)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{license}}{\code{string} containing the abbreviation of the license or
the license text.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TextEmbeddingClassifierNeuralNet-get_license"></a>}}
\if{latex}{\out{\hypertarget{method-TextEmbeddingClassifierNeuralNet-get_license}{}}}
\subsection{Method \code{get_license()}}{
Method for requesting the license of the classifier.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TextEmbeddingClassifierNeuralNet$get_license()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
\code{string} License of the classifier.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TextEmbeddingClassifierNeuralNet-set_model_description"></a>}}
\if{latex}{\out{\hypertarget{method-TextEmbeddingClassifierNeuralNet-set_model_description}{}}}
\subsection{Method \code{set_model_description()}}{
Method for setting a description of the classifier.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TextEmbeddingClassifierNeuralNet$set_model_description(
  eng = NULL,
  native = NULL
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{eng}}{\code{string} A text describing the training of the learner,
its theoretical and empirical background, and the different output labels
in English.}

\item{\code{native}}{\code{string} A text describing the training of the learner,
its theoretical and empirical background, and the different output labels
in the native language of the classifier.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TextEmbeddingClassifierNeuralNet-get_model_description"></a>}}
\if{latex}{\out{\hypertarget{method-TextEmbeddingClassifierNeuralNet-get_model_description}{}}}
\subsection{Method \code{get_model_description()}}{
Method for requesting the model description.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TextEmbeddingClassifierNeuralNet$get_model_description()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
\code{list} with the description of the classifier in English
and native language.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TextEmbeddingClassifierNeuralNet-export_model"></a>}}
\if{latex}{\out{\hypertarget{method-TextEmbeddingClassifierNeuralNet-export_model}{}}}
\subsection{Method \code{export_model()}}{
Method for exporting a model to tensorflow SavedModel format.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TextEmbeddingClassifierNeuralNet$export_model(dir_path)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{dir_path}}{\code{string()} Path of the directory where the model should be
saved.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TextEmbeddingClassifierNeuralNet-import_model"></a>}}
\if{latex}{\out{\hypertarget{method-TextEmbeddingClassifierNeuralNet-import_model}{}}}
\subsection{Method \code{import_model()}}{
Method for importing a model from tensorflow SavedModel format.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TextEmbeddingClassifierNeuralNet$import_model(dir_path)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{dir_path}}{\code{string()} Path of the directory where the model is
saved.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-TextEmbeddingClassifierNeuralNet-clone"></a>}}
\if{latex}{\out{\hypertarget{method-TextEmbeddingClassifierNeuralNet-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{TextEmbeddingClassifierNeuralNet$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
