#'@title Text embedding classifier with a neural net
#'
#'@description Abstract class for neural nets with 'keras'/'tensorflow' and
#''pytorch'.
#'
#'@return Objects of this class are used for assigning texts to classes/categories. For
#'the creation and training of a classifier an object of class \link{EmbeddedText} and a \code{factor}
#'are necessary. The object of class \link{EmbeddedText} contains the numerical text
#'representations (text embeddings) of the raw texts generated by an object of class
#'\link{TextEmbeddingModel}. The \code{factor} contains the classes/categories for every
#'text. Missing values (unlabeled cases) are supported. For predictions an object of class
#'\link{EmbeddedText} has to be used which was created with the same text embedding model as
#'for training.
#'@family Classification
#'@export
TEFeatureExtractor<-R6::R6Class(
  classname = "TEFeatureExtractor",
  inherit = AIFEBaseModel,
  public = list(
    #New-----------------------------------------------------------------------
    #'@description Creating a new instance of this class.
    #'@param ml_framework \code{string} Framework to use for training and inference.
    #'\code{ml_framework="tensorflow"} for 'tensorflow' and \code{ml_framework="pytorch"}
    #'for 'pytorch'
    #'@param name \code{Character} Name of the new classifier. Please refer to
    #'common name conventions. Free text can be used with parameter \code{label}.
    #'@param label \code{Character} Label for the new classifier. Here you can use
    #'free text.
    #'@param text_embeddings An object of class\code{TextEmbeddingModel}.
    #'@param features \code{int} determining the number of dimensions to which
    #'the dimension of the text embedding should be reduced.
    #'@param fe_method \code{string} Method to use for the feature extraction.
    #'\code{"lstm"} for an extractor based on LSTM-layers or \code{"dense"} for
    #'dense layers.
    #'@param noise_factor \code{double} between 0 and a value lower 1 indicating
    #'how much noise should be added for the training of the feature extractor.
    #'@param optimizer Object of class \code{keras.optimizers}.
    #'@return Returns an object of class \link{TEFeatureExtractor} which is ready for
    #'training.
    initialize=function(ml_framework=aifeducation_config$get_framework(),
                        name=NULL,
                        label=NULL,
                        text_embeddings=NULL,
                        features=128,
                        method="lstm",
                        noise_factor=0.2,
                        optimizer="adam"
    ){
      #Checking of parameters--------------------------------------------------
      if(is.null(name)){
        stop("name is NULL but must be a character.")
      }
      if(is.null(label)){
        stop("label is NULL but must be a character.")
      }
      if(!("EmbeddedText" %in% class(text_embeddings))){
        stop("text_embeddings must be of class EmbeddedText.")
      }

      if(optimizer %in% c("adam","rmsprop")==FALSE){
        stop("Optimzier must be 'adam' oder 'rmsprop'.")
      }

      if((ml_framework %in% c("tensorflow","pytorch"))==FALSE) {
        stop("ml_framework must be 'tensorflow' or 'pytorch'.")
      }

      private$ml_framework=ml_framework

      #Setting Label and Name-------------------------------------------------
      private$model_info$model_name_root=name
      private$model_info$model_name=paste0(private$model_info$model_name_root,"_ID_",generate_id(16))
      private$model_info$model_label=label

      #Basic Information of Input and Target Data
      model_info=text_embeddings$get_model_info()
      private$text_embedding_model["model"]=list(model_info)
      private$text_embedding_model["times"]=model_info$param_chunks
      private$text_embedding_model["features"]=dim(text_embeddings$embeddings)[3]

      #Saving Configuration
      config=list(
        method=method,
        noise_factor=noise_factor,
        features=features,
        times=private$text_embedding_model[["times"]],
        optimizer=optimizer,
        require_one_hot=FALSE,
        require_matrix_map=FALSE)

      self$model_config=config

      #Create_Model------------------------------------------------------------
      private$create_reset_model()

      private$model_info$model_date=date()

      private$r_package_versions$aifeducation<-packageVersion("aifeducation")
      private$r_package_versions$reticulate<-packageVersion("reticulate")

      private$py_package_versions$tensorflow<-tf$version$VERSION
      private$py_package_versions$torch<-torch["__version__"]
      private$py_package_versions$keras<-keras["__version__"]
      private$py_package_versions$numpy<-np$version$short_version
    },

    #-------------------------------------------------------------------------
    #'@description Method for training a neural net.
    #'@param data_embeddings Object of class \code{TextEmbeddingModel}.
    #'@param data_val_size \code{double} between 0 and 1, indicating the proportion of cases of each class
    #'which should be used for the validation sample during the estimation of the baseline model.
    #'The remaining cases are part of the training data.
    #'@param sustain_track \code{bool} If \code{TRUE} energy consumption is tracked
    #'during training via the python library codecarbon.
    #'@param sustain_iso_code \code{string} ISO code (Alpha-3-Code) for the country. This variable
    #'must be set if sustainability should be tracked. A list can be found on
    #'Wikipedia: \url{https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes}.
    #'@param sustain_region Region within a country. Only available for USA and
    #'Canada See the documentation of codecarbon for more information.
    #'\url{https://mlco2.github.io/codecarbon/parameters.html}
    #'@param sustain_interval \code{integer} Interval in seconds for measuring power
    #'usage.
    #'@param epochs \code{int} Number of training epochs.
    #'@param batch_size \code{int} Size of batches.
    #'@param dir_checkpoint \code{string} Path to the directory where
    #'the checkpoint during training should be saved. If the directory does not
    #'exist, it is created.
    #'@param trace \code{bool} \code{TRUE}, if information about the estimation
    #'phase should be printed to the console.
    #'@param keras_trace \code{int} \code{keras_trace=0} does not print any
    #'information about the training process from keras on the console.
    #'@param pytorch_trace \code{int} \code{pytorch_trace=0} does not print any
    #'information about the training process from pytorch on the console.
    #'\code{pytorch_trace=1} prints a progress bar.
    #'@return Function does not return a value. It changes the object into a trained
    #'classifier.
    #'@importFrom abind abind
    train=function(data_embeddings,
                   data_val_size=0.25,
                   sustain_track=TRUE,
                   sustain_iso_code=NULL,
                   sustain_region=NULL,
                   sustain_interval=15,
                   epochs=40,
                   batch_size=32,
                   dir_checkpoint,
                   trace=TRUE,
                   keras_trace=2,
                   pytorch_trace=1){

      #Checking Arguments------------------------------------------------------
      if(!("EmbeddedText" %in% class(data_embeddings))){
        stop("data_embeddings must be an object of class EmbeddedText")
      }

      if(self$check_embedding_model(data_embeddings)==FALSE){
        stop("The TextEmbeddingModel that generated the data_embeddings is not
               the same as the TextEmbeddingModel when generating the classifier.")
      }

      #Saving training configuration-------------------------------------------
      self$last_training$config$data_val_size=data_val_size
      self$last_training$config$sustain_track=sustain_track
      self$last_training$config$sustain_iso_code=sustain_iso_code
      self$last_training$config$sustain_region=sustain_region
      self$last_training$config$sustain_interval=sustain_interval
      self$last_training$config$epochs=epochs
      self$last_training$config$batch_size=batch_size
      self$last_training$config$dir_checkpoint=dir_checkpoint
      self$last_training$config$trace=trace
      self$last_training$config$keras_trace=keras_trace
      self$last_training$config$pytorch_trace=pytorch_trace

      #Loading PY Scripts
      private$load_reload_python_scripts()

      #Start-------------------------------------------------------------------
      if(self$last_training$config$trace==TRUE){
        message(paste(date(),
                      "Start"))
      }

      #Set up training and validation data
      if("EmbeddedText" %in% class(data_embeddings)){
        #Reduce to unique cases for training
        data=unique(data_embeddings$embeddings)

        #create a data set
        extractor_dataset=datasets$Dataset$from_dict(
          reticulate::dict(
            list(id=rownames(data),
                 input=np$squeeze(np$split(reticulate::np_array(data),as.integer(nrow(data)),axis=0L))),
            convert = FALSE))

        #remove data
        rm(data)

        #Copy input as label for training
        extractor_dataset=extractor_dataset$add_column("labels",extractor_dataset["input"])
      }

      if(private$ml_framework=="pytorch"){
        #Set format
        extractor_dataset$set_format("torch")

        #Split into train and validation data
        extractor_dataset=extractor_dataset$train_test_split(self$last_training$config$data_val_size)

        #Check directory for checkpoints
        if(dir.exists(paste0(self$last_training$config$dir_checkpoint,"/checkpoints"))==FALSE){
          if(self$last_training$config$trace==TRUE){
            message(paste(date(),"Creating Checkpoint Directory"))
          }
          dir.create(paste0(self$last_training$config$dir_checkpoint,"/checkpoints"))
        }
        #print(extractor_dataset$train)
        self$last_training$history=py$AutoencoderTrain_PT_with_Datasets(
          model=self$model,
          epochs=as.integer(self$last_training$config$epochs),
          trace=as.integer(self$last_training$config$pytorch_trace),
          batch_size=as.integer(self$last_training$config$batch_size),
          train_data=extractor_dataset$train,
          val_data=extractor_dataset$test,
          filepath=paste0(self$last_training$config$dir_checkpoint,"/best_weights.pt"),
          use_callback=TRUE,
          shiny_app_active=self$gui$shiny_app_active)$loss
      }

      rownames(self$last_training$history)=c("train","val")

      private$trained=TRUE
      if(self$last_training$config$trace==TRUE){
        message(paste(date(),"Training finished"))
      }
    },
    #--------------------------------------------------------------------------
    extract_features=function(data_embeddings,batch_size,return_r_object=TRUE){
        #Prepare data set
        if("EmbeddedText" %in% class(data_embeddings)){
          if(nrow(data_embeddings$embeddings)>1){
            extractor_dataset=datasets$Dataset$from_dict(
              reticulate::dict(
                list(id=rownames(data_embeddings$embeddings),
                     input=np$squeeze(np$split(reticulate::np_array(data_embeddings$embeddings),as.integer(nrow(data_embeddings$embeddings)),axis=0L))),
                convert = FALSE))
          } else {
            extractor_dataset=data_embeddings$embeddings
          }

        } else if("array" %in% class(data_embeddings)){
          if(nrow(data_embeddings)>1){
            extractor_dataset=datasets$Dataset$from_dict(
              reticulate::dict(
                list(id=rownames(data_embeddings),
                     input=np$squeeze(np$split(reticulate::np_array(data_embeddings),as.integer(nrow(data_embeddings)),axis=0L))),
                convert = FALSE))
          } else {
            extractor_dataset=data_embeddings
          }
        }

        #Extract features
        if(private$ml_framework=="pytorch"){
          if(torch$cuda$is_available()){
            device="cuda"
            dtype=torch$double

            if("datasets.arrow_dataset.Dataset"%in%class(extractor_dataset)){
              extractor_dataset$set_format("torch",device=device)
              self$model$to(device,dtype=dtype)
              self$model$eval()
              reduced_embeddings<-self$model(extractor_dataset["input"],
                                                               encoder_mode=TRUE)$detach()$cpu()$numpy()
            } else {
              self$model$to(device,dtype=dtype)
              self$model$eval()
              input=torch$from_numpy(np$array(extractor_dataset))
              reduced_embeddings<-self$model(input$to(device,dtype=dtype),
                                                               encoder_mode=TRUE)$detach()$cpu()$numpy()
            }
          } else {
            device="cpu"
            dtype=torch$float
            if("datasets.arrow_dataset.Dataset"%in%class(extractor_dataset)){
              extractor_dataset$set_format("torch",device=device)

              self$model$to(device,dtype=dtype)
              self$model$eval()
              reduced_embeddings<-self$model(extractor_dataset["input"],
                                                               encoder_mode=TRUE)$detach()$numpy()
            } else {
              self$model$to(device,dtype=dtype)
              self$model$eval()
              input=torch$from_numpy(np$array(extractor_dataset))
              reduced_embeddings<-self$model(input$to(device,dtype=dtype),
                                                               encoder_mode=TRUE)$detach()$numpy()
            }
          }
        }

        #Prepare output
        if(return_r_object==TRUE){
          reduced_embeddings=reduced_embeddings
          if("datasets.arrow_dataset.Dataset"%in%class(extractor_dataset)){
            rownames(reduced_embeddings)=extractor_dataset["id"]
          } else {
            rownames(reduced_embeddings)=rownames(data_embeddings)
          }


          model_info=self$get_text_embedding_model()

          reduced_embeddings=EmbeddedText$new(
            model_name=paste0("feature_extracted_",model_info$model_name),
            model_label=model_info$model_label,
            model_date=model_info$model_date,
            model_method=model_info$model_method,
            model_version=model_info$model_version,
            model_language=model_info$model_language,
            param_seq_length=model_info$param_seq_length,
            param_chunks=model_info$param_chunks,
            param_overlap=model_info$param_overlap,
            param_emb_layer_min=model_info$param_emb_layer_min,
            param_emb_layer_max=model_info$param_emb_layer_max,
            param_emb_pool_type=model_info$param_emb_pool_type,
            param_aggregation=model_info$param_aggregation,
            embeddings=reduced_embeddings)
          return(reduced_embeddings)
        }
    },
    is_trained=function(){
      return(private$trained)
    }
  ),
  private = list(
    trained=FALSE,
    #--------------------------------------------------------------------------
    load_reload_python_scripts=function(){
      if(private$ml_framework=="tensorflow"){
        reticulate::py_run_file(system.file("python/keras_te_classifier.py",
                                            package = "aifeducation"))
        reticulate::py_run_file(system.file("python/keras_callbacks.py",
                                            package = "aifeducation"))
      } else if(private$ml_framework=="pytorch"){
        reticulate::py_run_file(system.file("python/pytorch_te_classifier_V2.py",
                                            package = "aifeducation"))
        reticulate::py_run_file(system.file("python/pytorch_autoencoder.py",
                                            package = "aifeducation"))

      }
    },
    #--------------------------------------------------------------------------
    create_reset_model=function(){
      if(private$ml_framework=="pytorch"){
        if(self$model_config$method=="lstm"){
          self$model=py$LSTMAutoencoder_with_Mask_PT(
            times=as.integer(private$text_embedding_model["times"]),
            features_in=as.integer(private$text_embedding_model["features"]),
            features_out=as.integer(self$model_config$features),
            noise_factor=self$model_config$noise_factor)
        } else if(self$model_config$fe_method=="dense") {
          self$model=feature_extractor=py$DenseAutoencoder_with_Mask_PT(
            features_in=as.integer(private$text_embedding_model["features"]),
            features_out=as.integer(self$model_config$features),
            noise_factor=self$model_config$noise_factor)
        }
      } else if(private$ml_framework=="tensorflow"){
        features_in=as.integer(private$text_embedding_model["features"])
        features_out=as.integer(self$model_config$features)
        difference=features_in-features_out

        if(self$model_config$fe_method=="lstm"){

          LSTMAutoencoder_with_Mask<-NULL
          layer_list=NULL

          #Input layer
          layer_list[1]<-list(
            keras$layers$Input(shape=list(as.integer(private$text_embedding_model["times"]),features_in),
                               name="input_embeddings"))
          #Masking layer
          layer_list[length(layer_list)+1]=list(
            keras.layers.Masking(mask_value=0.0)
          )
          #Encoder
          layer_list[length(layer_list)+1]=list(
            keras$layers$LSTM(
              units=as.integer(ceiling(features_in-difference*(1/2))))(layer_list[length(layer_list)])
          )
          #Latent Space
          layer_list[length(layer_list)+1]=list(
            keras$layers$LSTM(
              units=as.integer(features_out))(layer_list[length(layer_list)])
          )
          #Decoder
          layer_list[length(layer_list)+1]=list(
            keras$layers$LSTM(
              units=as.integer(ceiling(features_in-difference*(1/2))))(layer_list[length(layer_list)])
          )
          layer_list[length(layer_list)+1]=list(
            keras$layers$LSTM(
              units=as.integer(features_in))(layer_list[length(layer_list)])
          )
        }
      }
    },
    #--------------------------------------------------------------------------
    init_gui=function(data_manager){
      #Check for a running Shiny App and set the configuration
      #The Gui functions must be set in the server function of shiny globally
      if(requireNamespace("shiny",quietly=TRUE) & requireNamespace("shinyWidgets",quietly=TRUE)){
        if(shiny::isRunning()){
          private$gui$shiny_app_active=TRUE
        } else {
          private$gui$shiny_app_active=FALSE
        }
      } else {
        private$gui$shiny_app_active=FALSE
      }

      #SetUp Progressbar for UI
      private$gui$pgr_value=-1
      private$gui$pgr_max_value=data_manager$get_n_folds()+1+
        (data_manager$get_n_folds()+1)*self$last_training$config$use_pl*self$last_training$config$pl_max_steps

    }
  )
)
