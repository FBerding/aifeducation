#'@title Text embedding classifier with a neural net
#'
#'@description Abstract class for neural nets with 'keras'/'tensorflow' and
#''pytorch'.
#'
#'@return Objects of this class are used for assigning texts to classes/categories. For
#'the creation and training of a classifier an object of class \link{EmbeddedText} and a \code{factor}
#'are necessary. The object of class \link{EmbeddedText} contains the numerical text
#'representations (text embeddings) of the raw texts generated by an object of class
#'\link{TextEmbeddingModel}. The \code{factor} contains the classes/categories for every
#'text. Missing values (unlabeled cases) are supported. For predictions an object of class
#'\link{EmbeddedText} has to be used which was created with the same text embedding model as
#'for training.
#'@family Classification
#'@export
TEFeatureExtractor<-R6::R6Class(
  classname = "TEFeatureExtractor",
  inherit = AIFEBaseModel,
  public = list(
    #New-----------------------------------------------------------------------
    #'@description Creating a new instance of this class.
    #'@param ml_framework \code{string} Framework to use for training and inference.
    #'\code{ml_framework="tensorflow"} for 'tensorflow' and \code{ml_framework="pytorch"}
    #'for 'pytorch'
    #'@param name \code{Character} Name of the new classifier. Please refer to
    #'common name conventions. Free text can be used with parameter \code{label}.
    #'@param label \code{Character} Label for the new classifier. Here you can use
    #'free text.
    #'@param text_embeddings An object of class\code{TextEmbeddingModel}.
    #'@param features \code{int} determining the number of dimensions to which
    #'the dimension of the text embedding should be reduced.
    #'@param fe_method \code{string} Method to use for the feature extraction.
    #'\code{"lstm"} for an extractor based on LSTM-layers or \code{"dense"} for
    #'dense layers.
    #'@param noise_factor \code{double} between 0 and a value lower 1 indicating
    #'how much noise should be added for the training of the feature extractor.
    #'@param optimizer Object of class \code{keras.optimizers}.
    #'@return Returns an object of class \link{TEFeatureExtractor} which is ready for
    #'training.
    initialize=function(ml_framework=aifeducation_config$get_framework(),
                        name=NULL,
                        label=NULL,
                        text_embeddings=NULL,
                        features=128,
                        method="lstm",
                        noise_factor=0.2,
                        optimizer="adam"
    ){
      #Checking of parameters--------------------------------------------------
      if(is.null(name)){
        stop("name is NULL but must be a character.")
      }
      if(is.null(label)){
        stop("label is NULL but must be a character.")
      }
      if(!("EmbeddedText" %in% class(text_embeddings))){
        stop("text_embeddings must be of class EmbeddedText.")
      }

      if(optimizer %in% c("adam","rmsprop")==FALSE){
        stop("Optimzier must be 'adam' oder 'rmsprop'.")
      }

      if((ml_framework %in% c("tensorflow","pytorch"))==FALSE) {
        stop("ml_framework must be 'tensorflow' or 'pytorch'.")
      }

      if(method%in%c("lstm","dense","conv")==FALSE){
        stop("Method must be lstm, dense or conv. Please check.")
      }
      if(ml_framework=="tensorflow" & method!="lstm"){
        stop("For tensorflow only the method lstm is implemented.")
      }

      private$ml_framework=ml_framework

      #Setting Label and Name-------------------------------------------------
      private$model_info$model_name_root=name
      private$model_info$model_name=paste0(private$model_info$model_name_root,"_ID_",generate_id(16))
      private$model_info$model_label=label

      #Basic Information of Input and Target Data
      model_info=text_embeddings$get_model_info()
      private$text_embedding_model["model"]=list(model_info)
      private$text_embedding_model["times"]=model_info$param_chunks
      private$text_embedding_model["features"]=dim(text_embeddings$embeddings)[3]

      #Saving Configuration
      config=list(
        method=method,
        noise_factor=noise_factor,
        features=features,
        times=private$text_embedding_model[["times"]],
        optimizer=optimizer,
        require_one_hot=FALSE,
        require_matrix_map=FALSE)

      self$model_config=config

      #Create_Model------------------------------------------------------------
      private$load_reload_python_scripts()
      private$create_reset_model()

      private$model_info$model_date=date()

      private$r_package_versions$aifeducation<-packageVersion("aifeducation")
      private$r_package_versions$reticulate<-packageVersion("reticulate")

      private$py_package_versions$tensorflow<-tf$version$VERSION
      private$py_package_versions$torch<-torch["__version__"]
      private$py_package_versions$keras<-keras["__version__"]
      private$py_package_versions$numpy<-np$version$short_version
    },

    #-------------------------------------------------------------------------
    #'@description Method for training a neural net.
    #'@param data_embeddings Object of class \code{TextEmbeddingModel}.
    #'@param data_val_size \code{double} between 0 and 1, indicating the proportion of cases of each class
    #'which should be used for the validation sample during the estimation of the baseline model.
    #'The remaining cases are part of the training data.
    #'@param sustain_track \code{bool} If \code{TRUE} energy consumption is tracked
    #'during training via the python library codecarbon.
    #'@param sustain_iso_code \code{string} ISO code (Alpha-3-Code) for the country. This variable
    #'must be set if sustainability should be tracked. A list can be found on
    #'Wikipedia: \url{https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes}.
    #'@param sustain_region Region within a country. Only available for USA and
    #'Canada See the documentation of codecarbon for more information.
    #'\url{https://mlco2.github.io/codecarbon/parameters.html}
    #'@param sustain_interval \code{integer} Interval in seconds for measuring power
    #'usage.
    #'@param epochs \code{int} Number of training epochs.
    #'@param batch_size \code{int} Size of batches.
    #'@param dir_checkpoint \code{string} Path to the directory where
    #'the checkpoint during training should be saved. If the directory does not
    #'exist, it is created.
    #'@param trace \code{bool} \code{TRUE}, if information about the estimation
    #'phase should be printed to the console.
    #'@param keras_trace \code{int} \code{keras_trace=0} does not print any
    #'information about the training process from keras on the console.
    #'@param pytorch_trace \code{int} \code{pytorch_trace=0} does not print any
    #'information about the training process from pytorch on the console.
    #'\code{pytorch_trace=1} prints a progress bar.
    #'@return Function does not return a value. It changes the object into a trained
    #'classifier.
    #'@importFrom abind abind
    train=function(data_embeddings,
                   data_val_size=0.25,
                   sustain_track=TRUE,
                   sustain_iso_code=NULL,
                   sustain_region=NULL,
                   sustain_interval=15,
                   epochs=40,
                   batch_size=32,
                   dir_checkpoint,
                   trace=TRUE,
                   keras_trace=2,
                   pytorch_trace=1){

      #Checking Arguments------------------------------------------------------
      self$check_embedding_model(data_embeddings)

      #Saving training configuration-------------------------------------------
      self$last_training$config$data_val_size=data_val_size
      self$last_training$config$sustain_track=sustain_track
      self$last_training$config$sustain_iso_code=sustain_iso_code
      self$last_training$config$sustain_region=sustain_region
      self$last_training$config$sustain_interval=sustain_interval
      self$last_training$config$epochs=epochs
      self$last_training$config$batch_size=batch_size
      self$last_training$config$dir_checkpoint=dir_checkpoint
      self$last_training$config$trace=trace
      self$last_training$config$keras_trace=keras_trace
      self$last_training$config$pytorch_trace=pytorch_trace

      #Loading PY Scripts
      private$load_reload_python_scripts()

      #Start-------------------------------------------------------------------
      if(self$last_training$config$trace==TRUE){
        message(paste(date(),
                      "Start"))
      }

      #Set up dataset
      if("EmbeddedText" %in% class(data_embeddings)){
        data=data_embeddings$convert_to_LargeDataSetForTextEmbeddings()
      }

      #Reduce to unique cases for training
      data=reduce_to_unique(data,"input")

      #Copy input as label for training
      #extractor_dataset=extractor_dataset$add_column("labels",extractor_dataset["input"])
      extractor_dataset=extractor_dataset$map(py$map_input_to_labels)

      #Check directory for checkpoints
      if(dir.exists(paste0(self$last_training$config$dir_checkpoint,"/checkpoints"))==FALSE){
        if(self$last_training$config$trace==TRUE){
          message(paste(date(),"Creating Checkpoint Directory"))
        }
        dir.create(paste0(self$last_training$config$dir_checkpoint,"/checkpoints"))
      }

      if(private$ml_framework=="pytorch"){
        #Set format
        extractor_dataset$set_format("torch")

        #Split into train and validation data
        extractor_dataset=extractor_dataset$train_test_split(self$last_training$config$data_val_size)

        #print(extractor_dataset$train)
        self$last_training$history=py$AutoencoderTrain_PT_with_Datasets(
          model=self$model,
          epochs=as.integer(self$last_training$config$epochs),
          trace=as.integer(self$last_training$config$pytorch_trace),
          batch_size=as.integer(self$last_training$config$batch_size),
          train_data=extractor_dataset$train,
          val_data=extractor_dataset$test,
          filepath=paste0(self$last_training$config$dir_checkpoint,"/best_weights.pt"),
          use_callback=TRUE,
          shiny_app_active=self$gui$shiny_app_active)$loss
        #-----------------------------------------------------------------------
      } else if(private$ml_framework=="tensorflow"){
        #Set format
        extractor_dataset$set_format("torch")

        #Split into train and validation data
        extractor_dataset=extractor_dataset$train_test_split(self$last_training$config$data_val_size)

        #Set Callback
        callback=keras$callbacks$ModelCheckpoint(
          filepath = paste0(self$last_training$config$dir_checkpoint,"/best_weights.keras"),
          monitor = "val_loss",
          verbose = as.integer(min(self$last_training$config$keras_trace,1)),
          mode = "auto",
          save_best_only = TRUE,
          save_weights_only = TRUE)

        #Set optimizer
        if(self$model_config$optimizer=="adam"){
          self$model$compile(
            loss = "MSE",
            optimizer=keras$optimizers$Adam())
        } else if (self$model_config$optimizer=="rmsprop"){
          self$model$compile(
            loss = "MSE",
            optimizer=keras$optimizers$RMSprop())
        }

          tf_dataset_train=extractor_dataset$train$to_tf_dataset(
            columns=c("input"),
            batch_size=as.integer(self$last_training$config$batch_size),
            shuffle=TRUE,
            label_cols="labels")

          tf_dataset_val=extractor_dataset$test$to_tf_dataset(
            columns=c("input"),
            batch_size=as.integer(self$last_training$config$batch_size),
            shuffle=FALSE,
            label_cols="labels")

          history<-self$model$fit(
            verbose=as.integer(self$last_training$config$keras_trace),
            x=tf_dataset_train,
            validation_data=tf_dataset_val,
            epochs = as.integer(self$last_training$config$epochs),
            callbacks = callback)$history

          history=rbind(history$loss,history$val_loss)
          self$last_training$history=history

          self$model$load_weights(paste0(self$last_training$config$dir_checkpoint,"/best_weights.keras"))

      }

      rownames(self$last_training$history)=c("train","val")

      private$trained=TRUE
      if(self$last_training$config$trace==TRUE){
        message(paste(date(),"Training finished"))
      }
    },
    #--------------------------------------------------------------------------
    extract_features=function(data_embeddings,batch_size){

      #check data_embeddings object
      if("EmbeddedText"%in%class(newdata)|
         "LargeDataSetForTextEmbeddings"%in%class(newdata)){
        self$check_embedding_model(text_embeddings=newdata,require_compressed = FALSE)
      } else {
        private$check_embeddings_object_type(newdata,strict=FALSE)
      }

      #Load Custom Model Scripts
      private$load_reload_python_scripts()

      #Check number of cases in the data
      single_prediction=private$check_single_prediction(data_embeddings)

      #Get current row names/name of the cases
      current_row_names=private$get_rownames_from_embeddings(data_embeddings)

      #If at least two cases are part of the data set---------------------------
      if(single_prediction==FALSE){
        prepared_embeddings=private$prepare_embeddings_as_dataset(data_embeddings)

        if(private$ml_framework=="pytorch"){
          prepared_embeddings$set_format("torch")
          reduced_tensors=py$TeFeatureExtractorBatchExtract(
            model=self$model,
            dataset=prepared_embeddings,
            batch_size=as.integer(batch_size)
          )
          reduced_embeddings=private$detach_tensors(reduced_tensors)
        } else if(private$ml_framework=="tensorflow"){
          prepared_embeddings$set_format("tf")
          prepared_embeddings_tf=prepared_embeddings$to_tf_dataset(
            columns=c("input"),
            batch_size=as.integer(batch_size),
            shuffle=FALSE)

          encoder_model= tf$keras$Model(inputs=self$model$input, outputs=self$model$get_layer("latent_space_output")$output)

          reduced_embeddings=encoder_model$predict(prepared_embeddings_tf)
        }
        #---------------------------------------------------------------------
      } else {
        prepared_embeddings=private$prepare_embeddings_as_np_array(data_embeddings)
        if(private$ml_framework=="pytorch"){
          if(torch$cuda$is_available()){
            device="cuda"
            dtype=torch$double
            self$model$to(device,dtype=dtype)
            self$model$eval()
            input=torch$from_numpy(prepared_embeddings)
            reduced_tensors<-self$model(input$to(device,dtype=dtype),
                                         encoder_mode=TRUE)
            reduced_embeddings=private$detach_tensors(reduced_tensors)
          } else {
            device="cpu"
            dtype=torch$float
            self$model$to(device,dtype=dtype)
            self$model$eval()
            input=torch$from_numpy(prepared_embeddings)
            reduced_tensors<-self$model(input$to(device,dtype=dtype),
                                        encoder_mode=TRUE)
            reduced_embeddings=private$detach_tensors(reduced_tensors)
          }
        } else if(private$ml_framework=="tensorflow"){
          encoder_model= tf$keras$Model(inputs=self$model$input, outputs=self$model$get_layer("latent_space_output")$output)
          reduced_embeddings=encoder_model$predict(prepared_embeddings)
        }
      }

        #Prepare output
          if("datasets.arrow_dataset.Dataset"%in%class(data_embeddings)){
            rownames(reduced_embeddings)=extractor_dataset["id"]
          } else {
            rownames(reduced_embeddings)=current_row_names
          }

          model_info=self$get_text_embedding_model()

          reduced_embeddings=EmbeddedText$new(
            model_name=paste0("feature_extracted_",model_info$model_name),
            model_label=model_info$model_label,
            model_date=model_info$model_date,
            model_method=model_info$model_method,
            model_version=model_info$model_version,
            model_language=model_info$model_language,
            param_seq_length=model_info$param_seq_length,
            param_features=dim(reduced_embeddings)[3],
            param_chunks=model_info$param_chunks,
            param_overlap=model_info$param_overlap,
            param_emb_layer_min=model_info$param_emb_layer_min,
            param_emb_layer_max=model_info$param_emb_layer_max,
            param_emb_pool_type=model_info$param_emb_pool_type,
            param_aggregation=model_info$param_aggregation,
            embeddings=reduced_embeddings)

          reduced_embeddings$add_feature_extractor_info(model_name=private$model_info$model_name,
                                                model_label=private$model_info$model_label,
                                                features=self$model_config$features,
                                                method=self$model_config$method,
                                                noise_factor=self$model_config$noise_factor,
                                                optimizer=self$model_config$optimizer)

    return(reduced_embeddings)

    },
    #--------------------------------------------------------------------------
    extract_features_large=function(data_embeddings,batch_size,trace=FALSE){
      #Get total number of batches for the loop
      total_number_of_bachtes=ceiling(data_embeddings$n_rows()/batch_size)

      #Get indices for every batch
      batches_index=get_batches_index(number_rows=data_embeddings$n_rows(),
                                      batch_size=batch_size,
                                      zero_based=TRUE)
      #Process every batch
      for(i in 1:total_number_of_bachtes){
        subset=data_embeddings$select(as.integer(batches_index[[i]]))
        embeddings=self$extract_features(
          data_embeddings = subset,
          batch_size=batch_size
        )
        if(i==1){
          #Create Large Dataset
          model_info=self$get_text_embedding_model()

          embedded_texts_large=LargeDataSetForTextEmbeddings$new(
            model_label=model_info$model_label,
            model_date=model_info$model_date,
            model_method=model_info$model_method,
            model_version=model_info$model_version,
            model_language=model_info$model_language,
            param_seq_length=model_info$param_seq_length,
            param_features=dim(reduced_embeddings)[3],
            param_chunks=model_info$param_chunks,
            param_overlap=model_info$param_overlap,
            param_emb_layer_min=model_info$param_emb_layer_min,
            param_emb_layer_max=model_info$param_emb_layer_max,
            param_emb_pool_type=model_info$param_emb_pool_type,
            param_aggregation=model_info$param_aggregation
            )
          embedded_texts_large$add_feature_extractor_info(model_name=private$model_info$model_name,
                                                        model_label=private$model_info$model_label,
                                                        features=self$model_config$features,
                                                        method=self$model_config$method,
                                                        noise_factor=self$model_config$noise_factor,
                                                        optimizer=self$model_config$optimizer)

          #Add new data
          embedded_texts_large$add_embeddings_from_EmbeddedText(embeddings)
        } else {
          #Add new data
          embedded_texts_large$add_embeddings_from_EmbeddedText(embeddings)
        }
        if(trace==TRUE){
          cat(paste(date(),
                    "Batch",i,"/",total_number_of_bachtes,"done","\n"))
        }
        gc()
      }
      return(embedded_texts_large)
    },
      #-----------------------------------------------------------------------
    is_trained=function(){
      return(private$trained)
    }
  ),
  private = list(
    trained=FALSE,
    #--------------------------------------------------------------------------
    load_reload_python_scripts=function(){
      reticulate::py_run_file(system.file("python/py_functions.py",
                                          package = "aifeducation"))
      if(private$ml_framework=="tensorflow"){
        reticulate::py_run_file(system.file("python/keras_autoencoder.py",
                                            package = "aifeducation"))
        reticulate::py_run_file(system.file("python/keras_callbacks.py",
                                            package = "aifeducation"))
      } else if(private$ml_framework=="pytorch"){
        reticulate::py_run_file(system.file("python/pytorch_te_classifier_V2.py",
                                            package = "aifeducation"))
        reticulate::py_run_file(system.file("python/pytorch_autoencoder.py",
                                            package = "aifeducation"))

      }
    },
    #--------------------------------------------------------------------------
    create_reset_model=function(){
      if(private$ml_framework=="pytorch"){
        if(self$model_config$method=="lstm"){
          self$model=py$LSTMAutoencoder_with_Mask_PT(
            times=as.integer(private$text_embedding_model["times"]),
            features_in=as.integer(private$text_embedding_model["features"]),
            features_out=as.integer(self$model_config$features),
            noise_factor=self$model_config$noise_factor)
        } else if(self$model_config$method=="dense") {
          self$model=feature_extractor=py$DenseAutoencoder_with_Mask_PT(
            features_in=as.integer(private$text_embedding_model["features"]),
            features_out=as.integer(self$model_config$features),
            noise_factor=self$model_config$noise_factor)
        } else if(self$model_config$method=="conv") {
          self$model=feature_extractor=py$ConvAutoencoder_with_Mask_PT(
            features_in=as.integer(private$text_embedding_model["features"]),
            features_out=as.integer(self$model_config$features),
            noise_factor=self$model_config$noise_factor)
        }
      } else if(private$ml_framework=="tensorflow"){
        if(self$model_config$method=="lstm"){
          self$model=py$LSTMAutoencoder_with_Mask_TF(
            times=as.integer(private$text_embedding_model["times"]),
            features_in=as.integer(private$text_embedding_model["features"]),
            features_out=as.integer(self$model_config$features),
            noise_factor=self$model_config$noise_factor)
        }
      }
    },
    #--------------------------------------------------------------------------
    init_gui=function(data_manager){
      #Check for a running Shiny App and set the configuration
      #The Gui functions must be set in the server function of shiny globally
      if(requireNamespace("shiny",quietly=TRUE) & requireNamespace("shinyWidgets",quietly=TRUE)){
        if(shiny::isRunning()){
          private$gui$shiny_app_active=TRUE
        } else {
          private$gui$shiny_app_active=FALSE
        }
      } else {
        private$gui$shiny_app_active=FALSE
      }

      #SetUp Progressbar for UI
      private$gui$pgr_value=-1
      private$gui$pgr_max_value=data_manager$get_n_folds()+1+
        (data_manager$get_n_folds()+1)*self$last_training$config$use_pl*self$last_training$config$pl_max_steps

    }
  )
)
