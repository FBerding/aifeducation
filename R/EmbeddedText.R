#'@title Embedded text
#'@description Object of class \link[R6]{R6} which stores the text embeddings
#'generated by an object of class \link{TextEmbeddingModel} via the method
#'\code{embed()}.
#'@return Returns an object of class \code{EmbeddedText}. These objects are used
#'for storing and managing the text embeddings created with objects of class \link{TextEmbeddingModel}.
#'Objects of class \code{EmbeddedText} serve as input for classifiers of class
#'\link{TextEmbeddingClassifierNeuralNet}. The main aim of this class is to provide a structured link between
#'embedding models and classifiers. Since objects of this class save information on
#'the text embedding model that created the text embedding it ensures that only
#'embedding generated with same embedding model are combined. Furthermore, the stored information allows
#'classifiers to check if embeddings of the correct text embedding model are used for
#'training and predicting.
#'@family Text Embedding
#'@export
EmbeddedText<-R6::R6Class(
  classname = "EmbeddedText",
  private = list(

    #model_name \code{string} Name of the model that generates this embedding.
    model_name=NA,


    #Label of the model that generates this embedding.
    model_label=NA,


    #Date when the embedding generating model was created.
    model_date=NA,


    #Method of the underlying embedding model
    model_method=NA,


    #Version of the model that generated this embedding.
    model_version=NA,


    #Language of the model that generated this embedding.
    model_language=NA,


    #Maximal number of tokens that processes the generating model for a chunk.
    param_seq_length=NA,


    #Number of tokens that were added at the beginning of the sequence for the next chunk
    #by this model.
    param_overlap=NA,


    #Maximal number of chunks which are supported by the generating model.
    param_chunks=NA,

    #Features of the embeddings
    param_features=NA,

    #Minimal layer to be included in the creation of embeddings.
    param_emb_layer_min=NA,

    #Maximal layer to be included in the creation of embeddings.
    param_emb_layer_max=NA,

    #Type of pooling tokens embeddings within each layer.
    param_emb_pool_type=NA,


    #Aggregation method of the hidden states. Deprecated. Included for backward
    #compatibility.
    param_aggregation=NA,

    #List containing information on the feature extractor if the embeddings
    #are compressed.
    feature_extractor=list()
  ),
  public = list(
    #'@field embeddings ('data.frame()')\cr
    #'data.frame containing the text embeddings for all chunks. Documents are
    #'in the rows. Embedding dimensions are in the columns.
    embeddings=NA,

    #'@description Creates a new object representing text embeddings.
    #'@param model_name \code{string} Name of the model that generates this embedding.
    #'@param model_label \code{string} Label of the model that generates this embedding.
    #'@param model_date \code{string} Date when the embedding generating model was created.
    #'@param model_method \code{string} Method of the underlying embedding model.
    #'@param model_version \code{string} Version of the model that generated this embedding.
    #'@param model_language \code{string} Language of the model that generated this embedding.
    #'@param param_seq_length \code{int} Maximum number of tokens that processes the generating model for a chunk.
    #'@param param_chunks \code{int} Maximum number of chunks which are supported by the generating model.
    #'@param param_overlap \code{int} Number of tokens that were added at the beginning of the sequence for the next chunk
    #'by this model.
    #'
    #'@param param_emb_layer_min \code{int} or \code{string} determining the first layer to be included
    #'in the creation of embeddings.
    #'@param param_emb_layer_max \code{int} or \code{string} determining the last layer to be included
    #'in the creation of embeddings.
    #'@param param_emb_pool_type \code{string} determining the method for pooling the token embeddings
    #'within each layer.
    #'
    #'@param param_aggregation \code{string} Aggregation method of the hidden states. Deprecated. Only included
    #'for backward compatibility.
    #'@param embeddings \code{data.frame} containing the text embeddings.
    #'@return Returns an object of class \link{EmbeddedText} which stores the
    #'text embeddings produced by an objects of class \link{TextEmbeddingModel}.
    #'The object serves as input for objects of class \link{TextEmbeddingClassifierNeuralNet}.
    initialize=function(model_name=NA,
                        model_label=NA,
                        model_date=NA,
                        model_method=NA,
                        model_version=NA,
                        model_language=NA,
                        param_seq_length=NA,
                        param_chunks=NULL,
                        param_features=NULL,
                        param_overlap=NULL,
                        param_emb_layer_min=NULL,
                        param_emb_layer_max=NULL,
                        param_emb_pool_type=NULL,
                        param_aggregation=NULL,
                        embeddings){
      private$model_name = model_name
      private$model_label = model_label
      private$model_date = model_date
      private$model_method = model_method
      private$model_version = model_version
      private$model_language = model_language
      private$param_seq_length = param_seq_length
      private$param_chunks = param_chunks
      private$param_features=param_features
      private$param_overlap = param_overlap


      private$param_emb_layer_min=param_emb_layer_min
      private$param_emb_layer_max=param_emb_layer_max
      private$param_emb_pool_type=param_emb_pool_type

      private$param_aggregation = param_aggregation

      self$embeddings=embeddings
    },
    #--------------------------------------------------------------------------
    #'@description Method for retrieving information about the model that
    #'generated this embedding.
    #'@return \code{list} contains all saved information about the underlying
    #'text embedding model.
    get_model_info=function(){
      tmp<-list(model_name=private$model_name,
                model_label=private$model_label,
                model_date=private$model_date,
                model_method=private$model_method,
                model_version=private$model_version,
                model_language=private$model_language,
                param_seq_length=private$param_seq_length,
                param_chunks=private$param_chunks,
                param_overlap=private$param_overlap,
                param_emb_layer_min=private$param_emb_layer_min,
                param_emb_layer_max=private$param_emb_layer_max,
                param_emb_pool_type=private$param_emb_pool_type,
                param_aggregation=private$param_aggregation)
      return(tmp)
    },
    #--------------------------------------------------------------------------
    #'@description Method for retrieving the label of the model that
    #'generated this embedding.
    #'@return \code{string} Label of the corresponding text embedding model
    get_model_label=function(){
      return(private$transformer_components$ml_framework)
    },
    #--------------------------------------------------------------------------
    get_times=function(){
      return(private$param_chunks)
    },
    #--------------------------------------------------------------------------
    get_features=function(){
      if(self$is_compressed()==TRUE){
        return(private$feature_extractor$features)
      } else {
        return(private$param_features)
      }
    },
    #-------------------------------------------------------------------------
    get_original_features=function(){
      return(private$param_features)
    },
    #------------------------------------------------------------------------
    is_compressed=function(){
      if(is.null_or_na(private$feature_extractor$model_name)){
        return(FALSE)
      } else {
        return(TRUE)
      }
    },
    #--------------------------------------------------------------------------
    add_feature_extractor_info=function(model_name,
                                        model_label=NA,
                                        features=NA,
                                        method=NA,
                                        noise_factor=NA,
                                        optimizer=NA){
      private$feature_extractor=list(
        model_name=model_name,
        model_label=model_label,
        features=features,
        method=method,
        noise_factor=noise_factor,
        optimizer=optimizer
      )
    },
    #--------------------------------------------------------------------------
    get_feature_extractor_info=function(){
      if(is.null_or_na(private$feature_extractor$model_name)){
        return(NULL)
      } else {
        return(private$feature_extractor)
      }
    },
    #-------------------------------------------------------------------------
    convert_to_LargeDataSetForTextEmbeddings=function(){
      new_data_set=LargeDataSetForTextEmbeddings$new(
        model_name=private$model_name,
        model_label=private$model_label,
        model_date=private$model_date,
        model_method=private$model_method,
        model_version=private$model_version,
        model_language=private$model_language,
        param_seq_length=private$param_seq_length,
        param_chunks=private$param_chunks,
        param_features=private$param_features,
        param_overlap=private$param_overlap,
        param_emb_layer_min=private$param_emb_layer_min,
        param_emb_layer_max=private$param_emb_layer_max,
        param_emb_pool_type=private$param_emb_pool_type,
        param_aggregation=private$param_aggregation
      )

      if(self$is_compressed()==TRUE){
        new_data_set$add_feature_extractor_info(
          model_name=private$feature_extractor$model_name,
          model_label=private$feature_extractor$model_label,
          features=private$feature_extractor$features,
          method=private$feature_extractor$method,
          noise_factor=private$feature_extractor$noise_factor,
          optimizer=private$feature_extractor$optimizer
        )
      }

      new_data_set$add_embeddings_from_array(self$embeddings)
      return(new_data_set)
    }
  )
)

#'Combine embedded texts
#'
#'Function for combining embedded texts of the same model
#'
#'@param embeddings_list \code{list} of objects of class \link{EmbeddedText}.
#'@return Returns an object of class \link{EmbeddedText} which contains all
#'unique cases of the input objects.
#'@family Text Embedding
#'@export
#'@importFrom methods isClass
#'@importFrom abind abind
combine_embeddings<-function(embeddings_list){

  #Check for the right class---------------------------------------------------
  for(i in 1:length(embeddings_list)){
    if(methods::isClass(where=embeddings_list[[i]],
                        Class="EmbeddedText")==TRUE){
      stop("All elements of the embeddings_list must be of class
           EmbeddedText.")
    }
  }

  #Check for the right underlining embedding model-------------------------------
  result<-check_embedding_models(object_list = embeddings_list,
                                 same_class = FALSE)
  if(result==FALSE){
    stop("The models which created the embeddings are not similar
           accros all elements in embeddings_list. Please check
           the elements.")
  }


  #Check for unique names------------------------------------------------------
  tmp_names=NULL
  tmp_cases=NULL
  for(i in 1:length(embeddings_list)){
    if(i==1){
      tmp_names=rownames(embeddings_list[[i]]$embeddings)
      tmp_cases=nrow(embeddings_list[[i]]$embeddings)
    } else {
      tmp_names=c(tmp_names,rownames(embeddings_list[[i]]$embeddings))
      tmp_cases=tmp_cases+nrow(embeddings_list[[i]]$embeddings)
    }
  }
  tmp_names=unique(tmp_names)
  if(length(tmp_names)<tmp_cases){
    stop("There are cases with duplicated names. Please check your data. Names
         must be unique.")
  }


  #Combine embeddings-----------------------------------------------------------

  for(i in 1:length(embeddings_list)){
    if(i==1){
      combined_embeddings<-embeddings_list[[i]]$embeddings
    } else {
      combined_embeddings<-abind::abind(combined_embeddings,embeddings_list[[i]]$embeddings,
                                        along = 1)
    }
  }

  new_embedding<-EmbeddedText$new(
    embeddings = combined_embeddings,
    model_name = embeddings_list[[1]]$get_model_info()$model_name,
    model_label = embeddings_list[[1]]$get_model_info()$model_label,
    model_date =embeddings_list[[1]]$get_model_info()$model_date,
    model_method=embeddings_list[[1]]$get_model_info()$model_method,
    model_version=embeddings_list[[1]]$get_model_info()$model_version,
    model_language=embeddings_list[[1]]$get_model_info()$model_language,
    param_seq_length=embeddings_list[[1]]$get_model_info()$param_seq_length,
    param_chunks=embeddings_list[[1]]$get_model_info()$param_chunks,
    param_overlap=embeddings_list[[1]]$get_model_info()$param_overlap,

    param_emb_layer_min=embeddings_list[[1]]$get_model_info()$param_emb_layer_min,
    param_emb_layer_max=embeddings_list[[1]]$get_model_info()$param_emb_layer_max,
    param_emb_pool_type=embeddings_list[[1]]$get_model_info()$param_emb_pool_type,

    param_aggregation=embeddings_list[[1]]$get_model_info()$param_aggregation

  )

  return(new_embedding)
}
